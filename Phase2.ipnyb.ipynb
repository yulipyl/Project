{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 - Import the Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import ta  # Technical Analysis library\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2 – Define the training time frame\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "## Step 3 - Helper Functions\n",
    "def get_dow30_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average#Components'\n",
    "    tables = pd.read_html(url)\n",
    "    dow30_table = tables[1]\n",
    "    tickers = dow30_table['Symbol'].tolist()\n",
    "    return tickers\n",
    "\n",
    "def load_stock_data(ticker, start_date, end_date):\n",
    "    ticker = ticker.replace('.', '-')\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data['returns'] = data['Adj Close'].pct_change().fillna(0)\n",
    "    data['direction'] = np.where(data['Adj Close'].shift(-1) > data['Adj Close'], 1, 0)\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    print(f\"Initial data shape: {data.shape}\")\n",
    "\n",
    "    # Applying MACD\n",
    "    data['macd'] = ta.trend.macd(data['Adj Close']).fillna(0)\n",
    "\n",
    "    # Applying Bollinger Bands\n",
    "    bollinger = ta.volatility.BollingerBands(data['Adj Close'])\n",
    "    data['boll_ub'] = bollinger.bollinger_hband().fillna(data['Adj Close'])\n",
    "    data['boll_lb'] = bollinger.bollinger_lband().fillna(data['Adj Close'])\n",
    "\n",
    "    # Applying RSI\n",
    "    data['rsi_30'] = ta.momentum.RSIIndicator(data['Adj Close'], window=30).rsi().fillna(50)\n",
    "\n",
    "    # Applying ADX\n",
    "    if len(data) >= 30:\n",
    "        adx = ta.trend.ADXIndicator(data['High'], data['Low'], data['Adj Close'], window=30)\n",
    "        data['dx_30'] = adx.adx().fillna(20)\n",
    "    else:\n",
    "        data['dx_30'] = np.nan\n",
    "\n",
    "    # SMA\n",
    "    data['close_30_sma'] = data['Adj Close'].rolling(window=30).mean().ffill()\n",
    "    data['close_60_sma'] = data['Adj Close'].rolling(window=60).mean().bfill()\n",
    "\n",
    "    # Dropping NaN values\n",
    "    data.dropna(inplace=True)\n",
    "    print(f\"After dropping NaN values: {data.shape}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data_for_modeling(data, features):\n",
    "    output_var = data[['direction']]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    feature_transform = scaler.fit_transform(data[features])\n",
    "    feature_transform = pd.DataFrame(feature_transform, columns=features, index=data.index)\n",
    "\n",
    "    output_var = output_var.values.ravel()\n",
    "\n",
    "    train_size = int(len(feature_transform) * 0.8)\n",
    "    X_train, X_test = feature_transform[:train_size], feature_transform[train_size:]\n",
    "    y_train, y_test = output_var[:train_size], output_var[train_size:]\n",
    "\n",
    "    X_train = X_train.to_numpy().reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.to_numpy().reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MMM...\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.389954\n",
      "2023-12-26  2.450287\n",
      "2023-12-27  2.510682\n",
      "2023-12-28  2.591288\n",
      "2023-12-29  2.600801\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  88.913152  79.275502\n",
      "2023-12-26  89.163122  79.927264\n",
      "2023-12-27  89.539265  80.386694\n",
      "2023-12-28  89.924442  80.917952\n",
      "2023-12-29  90.143257  81.536343\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.468146\n",
      "2023-12-26  64.418466\n",
      "2023-12-27  65.082806\n",
      "2023-12-28  66.071003\n",
      "2023-12-29  65.326090\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.019013\n",
      "2023-12-26  18.226646\n",
      "2023-12-27  18.471283\n",
      "2023-12-28  18.798848\n",
      "2023-12-29  19.115495\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     81.731357     77.002458\n",
      "2023-12-26     82.187066     77.219457\n",
      "2023-12-27     82.663144     77.490600\n",
      "2023-12-28     83.103974     77.793840\n",
      "2023-12-29     83.485141     78.102363\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5462 - loss: 0.6918 - val_accuracy: 0.4659 - val_loss: 0.6968\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6902 - val_accuracy: 0.4659 - val_loss: 0.6973\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6900 - val_accuracy: 0.4659 - val_loss: 0.6979\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.6898 - val_accuracy: 0.4659 - val_loss: 0.6983\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6896 - val_accuracy: 0.4659 - val_loss: 0.6987\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.6895 - val_accuracy: 0.4659 - val_loss: 0.6990\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6894 - val_accuracy: 0.4659 - val_loss: 0.6994\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.6893 - val_accuracy: 0.4659 - val_loss: 0.6996\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.6892 - val_accuracy: 0.4659 - val_loss: 0.7000\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6891 - val_accuracy: 0.4659 - val_loss: 0.7002\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6890 - val_accuracy: 0.4659 - val_loss: 0.7005\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "MMM - Accuracy: 0.4659, Precision: 0.4659, Recall: 1.0000, F1 Score: 0.6356\n",
      "Processing AXP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  6.506604\n",
      "2023-12-26  6.583286\n",
      "2023-12-27  6.655277\n",
      "2023-12-28  6.694323\n",
      "2023-12-29  6.612270\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  186.207809  158.873356\n",
      "2023-12-26  187.387964  159.864926\n",
      "2023-12-27  188.623254  160.749842\n",
      "2023-12-28  189.856706  161.534548\n",
      "2023-12-29  190.974155  162.058772\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  68.217054\n",
      "2023-12-26  68.435078\n",
      "2023-12-27  69.054447\n",
      "2023-12-28  69.471335\n",
      "2023-12-29  68.874685\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  23.561045\n",
      "2023-12-26  24.094964\n",
      "2023-12-27  24.652370\n",
      "2023-12-28  25.231737\n",
      "2023-12-29  25.741996\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    167.900736    157.526338\n",
      "2023-12-26    168.943666    158.143583\n",
      "2023-12-27    170.024244    158.774223\n",
      "2023-12-28    171.044386    159.489933\n",
      "2023-12-29    171.966114    160.172064\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5117 - loss: 0.6931 - val_accuracy: 0.4980 - val_loss: 0.6954\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6956\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6952\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6951\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6949\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6948\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6947\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6946\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6945\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6929 - val_accuracy: 0.4980 - val_loss: 0.6944\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6929 - val_accuracy: 0.4980 - val_loss: 0.6943\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6943\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5134 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.6927 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.6927 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.6927 - val_accuracy: 0.4980 - val_loss: 0.6942\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6927 - val_accuracy: 0.4940 - val_loss: 0.6942\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6927 - val_accuracy: 0.4940 - val_loss: 0.6942\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6926 - val_accuracy: 0.4960 - val_loss: 0.6943\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6926 - val_accuracy: 0.4960 - val_loss: 0.6943\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "AXP - Accuracy: 0.4980, Precision: 0.4980, Recall: 1.0000, F1 Score: 0.6649\n",
      "Processing AMGN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.190549\n",
      "2023-12-26  3.534258\n",
      "2023-12-27  3.969977\n",
      "2023-12-28  4.417798\n",
      "2023-12-29  4.683726\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  279.187840  259.128633\n",
      "2023-12-26  280.307673  259.942837\n",
      "2023-12-27  281.861911  260.458600\n",
      "2023-12-28  283.616289  260.857970\n",
      "2023-12-29  285.149305  261.135830\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  59.519291\n",
      "2023-12-26  59.329459\n",
      "2023-12-27  60.642995\n",
      "2023-12-28  61.584851\n",
      "2023-12-29  61.239201\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  11.614499\n",
      "2023-12-26  11.834366\n",
      "2023-12-27  12.151005\n",
      "2023-12-28  12.525772\n",
      "2023-12-29  12.810566\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    266.838560    266.268769\n",
      "2023-12-26    267.451888    266.551808\n",
      "2023-12-27    268.171791    266.917952\n",
      "2023-12-28    268.846570    267.402138\n",
      "2023-12-29    269.408817    267.806922\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5147 - loss: 0.6929 - val_accuracy: 0.4859 - val_loss: 0.6939\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6921 - val_accuracy: 0.4859 - val_loss: 0.6938\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6918 - val_accuracy: 0.4859 - val_loss: 0.6935\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6916 - val_accuracy: 0.4859 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5285 - loss: 0.6915 - val_accuracy: 0.5281 - val_loss: 0.6927\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6914 - val_accuracy: 0.5221 - val_loss: 0.6924\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6914 - val_accuracy: 0.5422 - val_loss: 0.6921\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.6913 - val_accuracy: 0.5241 - val_loss: 0.6918\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6912 - val_accuracy: 0.5141 - val_loss: 0.6917\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5286 - loss: 0.6912 - val_accuracy: 0.5261 - val_loss: 0.6914\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6912 - val_accuracy: 0.5321 - val_loss: 0.6913\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6912 - val_accuracy: 0.5261 - val_loss: 0.6912\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6911 - val_accuracy: 0.5241 - val_loss: 0.6910\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6911 - val_accuracy: 0.5181 - val_loss: 0.6909\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.6910 - val_accuracy: 0.5201 - val_loss: 0.6909\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6910 - val_accuracy: 0.5241 - val_loss: 0.6908\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6910 - val_accuracy: 0.5221 - val_loss: 0.6907\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6910 - val_accuracy: 0.5241 - val_loss: 0.6907\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5288 - loss: 0.6909 - val_accuracy: 0.5281 - val_loss: 0.6906\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6909 - val_accuracy: 0.5281 - val_loss: 0.6905\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6909 - val_accuracy: 0.5301 - val_loss: 0.6905\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5288 - loss: 0.6908 - val_accuracy: 0.5301 - val_loss: 0.6905\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5289 - loss: 0.6908 - val_accuracy: 0.5301 - val_loss: 0.6904\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 0.6907 - val_accuracy: 0.5301 - val_loss: 0.6904\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6907 - val_accuracy: 0.5341 - val_loss: 0.6904\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5287 - loss: 0.6907 - val_accuracy: 0.5321 - val_loss: 0.6904\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5287 - loss: 0.6906 - val_accuracy: 0.5321 - val_loss: 0.6903\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5287 - loss: 0.6906 - val_accuracy: 0.5321 - val_loss: 0.6903\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5289 - loss: 0.6906 - val_accuracy: 0.5341 - val_loss: 0.6903\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6905 - val_accuracy: 0.5341 - val_loss: 0.6903\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6905 - val_accuracy: 0.5301 - val_loss: 0.6903\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5292 - loss: 0.6904 - val_accuracy: 0.5301 - val_loss: 0.6903\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 0.6904 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6903 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5307 - loss: 0.6903 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6903 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5303 - loss: 0.6902 - val_accuracy: 0.5201 - val_loss: 0.6902\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5297 - loss: 0.6901 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5297 - loss: 0.6901 - val_accuracy: 0.5221 - val_loss: 0.6902\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6900 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5300 - loss: 0.6900 - val_accuracy: 0.5201 - val_loss: 0.6901\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 0.6900 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5304 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 0.6899 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6898 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5298 - loss: 0.6898 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6897 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5293 - loss: 0.6897 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6897 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6896 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6896 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5288 - loss: 0.6895 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6895 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5279 - loss: 0.6895 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5276 - loss: 0.6894 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5282 - loss: 0.6894 - val_accuracy: 0.5181 - val_loss: 0.6901\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5284 - loss: 0.6894 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 59/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5266 - loss: 0.6893 - val_accuracy: 0.5161 - val_loss: 0.6901\n",
      "Epoch 60/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5283 - loss: 0.6893 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 61/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6892 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 62/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6892 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 63/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 0.6892 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 64/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6892 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 65/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.6891 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 66/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6891 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 67/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5305 - loss: 0.6891 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 68/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 0.6890 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 69/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 0.6890 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 70/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5348 - loss: 0.6890 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 71/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6889 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 72/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.6889 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 73/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5354 - loss: 0.6889 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 74/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6889 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 75/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5340 - loss: 0.6888 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 76/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5334 - loss: 0.6888 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 77/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5339 - loss: 0.6888 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 78/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5352 - loss: 0.6887 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 79/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 0.6887 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 80/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5356 - loss: 0.6887 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 81/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5379 - loss: 0.6886 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 82/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6886 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 83/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.6886 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 84/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5366 - loss: 0.6886 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 85/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5310 - loss: 0.6886 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 86/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5345 - loss: 0.6885 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 87/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 0.6885 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 88/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5347 - loss: 0.6885 - val_accuracy: 0.5181 - val_loss: 0.6900\n",
      "Epoch 89/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 0.6885 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 90/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 0.6884 - val_accuracy: 0.5161 - val_loss: 0.6900\n",
      "Epoch 91/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5310 - loss: 0.6884 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 92/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5334 - loss: 0.6884 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 93/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5305 - loss: 0.6883 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 94/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.6883 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 95/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6883 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 96/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6883 - val_accuracy: 0.5201 - val_loss: 0.6900\n",
      "Epoch 97/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5320 - loss: 0.6883 - val_accuracy: 0.5201 - val_loss: 0.6899\n",
      "Epoch 98/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6882 - val_accuracy: 0.5221 - val_loss: 0.6899\n",
      "Epoch 99/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5293 - loss: 0.6882 - val_accuracy: 0.5221 - val_loss: 0.6899\n",
      "Epoch 100/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6882 - val_accuracy: 0.5221 - val_loss: 0.6899\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "AMGN - Accuracy: 0.5221, Precision: 0.5323, Recall: 0.1364, F1 Score: 0.2171\n",
      "Processing AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.135958\n",
      "2023-12-26  3.118650\n",
      "2023-12-27  3.063965\n",
      "2023-12-28  2.989395\n",
      "2023-12-29  2.782032\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  154.696716  142.461283\n",
      "2023-12-26  155.314929  142.411071\n",
      "2023-12-27  155.854273  142.502726\n",
      "2023-12-28  156.311164  142.751835\n",
      "2023-12-29  156.488309  143.159691\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  60.603073\n",
      "2023-12-26  60.591470\n",
      "2023-12-27  60.507526\n",
      "2023-12-28  60.539846\n",
      "2023-12-29  58.749686\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  13.690745\n",
      "2023-12-26  13.829861\n",
      "2023-12-27  14.013525\n",
      "2023-12-28  14.175419\n",
      "2023-12-29  14.157813\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    147.274000    139.104500\n",
      "2023-12-26    147.602333    139.542667\n",
      "2023-12-27    147.960666    139.940667\n",
      "2023-12-28    148.213333    140.418333\n",
      "2023-12-29    148.504667    140.834000\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5170 - loss: 0.6920 - val_accuracy: 0.5040 - val_loss: 0.6955\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6907 - val_accuracy: 0.5040 - val_loss: 0.6953\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6903 - val_accuracy: 0.5040 - val_loss: 0.6951\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6902 - val_accuracy: 0.5040 - val_loss: 0.6949\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6900 - val_accuracy: 0.5040 - val_loss: 0.6947\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6900 - val_accuracy: 0.5040 - val_loss: 0.6946\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6899 - val_accuracy: 0.5040 - val_loss: 0.6945\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6899 - val_accuracy: 0.5040 - val_loss: 0.6944\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6899 - val_accuracy: 0.5040 - val_loss: 0.6943\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6898 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6897 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6896 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6895 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6894 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6893 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6892 - val_accuracy: 0.5040 - val_loss: 0.6942\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6891 - val_accuracy: 0.5040 - val_loss: 0.6943\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6890 - val_accuracy: 0.5040 - val_loss: 0.6943\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6889 - val_accuracy: 0.5040 - val_loss: 0.6943\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6888 - val_accuracy: 0.5040 - val_loss: 0.6944\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5423 - loss: 0.6887 - val_accuracy: 0.5040 - val_loss: 0.6944\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5425 - loss: 0.6886 - val_accuracy: 0.5040 - val_loss: 0.6944\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5403 - loss: 0.6885 - val_accuracy: 0.5040 - val_loss: 0.6945\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 0.6884 - val_accuracy: 0.5040 - val_loss: 0.6945\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "AMZN - Accuracy: 0.5040, Precision: 0.5040, Recall: 1.0000, F1 Score: 0.6702\n",
      "Processing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.647959\n",
      "2023-12-26  2.317722\n",
      "2023-12-27  2.040522\n",
      "2023-12-28  1.834263\n",
      "2023-12-29  1.568314\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  198.589529  187.283218\n",
      "2023-12-26  198.478607  187.718909\n",
      "2023-12-27  198.395451  188.076026\n",
      "2023-12-28  198.165457  188.725429\n",
      "2023-12-29  197.955942  189.191968\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.254946\n",
      "2023-12-26  56.555370\n",
      "2023-12-27  56.654974\n",
      "2023-12-28  57.092629\n",
      "2023-12-29  55.672685\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.320859\n",
      "2023-12-26  18.198209\n",
      "2023-12-27  17.919517\n",
      "2023-12-28  17.734529\n",
      "2023-12-29  17.425307\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    191.366830    183.044050\n",
      "2023-12-26    191.587659    183.410415\n",
      "2023-12-27    191.864940    183.736321\n",
      "2023-12-28    192.068834    184.091753\n",
      "2023-12-29    192.218931    184.408858\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5230 - loss: 0.6925 - val_accuracy: 0.5161 - val_loss: 0.6943\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6942\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6940\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6938\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6936\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6934\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6933\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6933\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6920 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6920 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6920 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6919 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6919 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6918 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6918 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6917 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6917 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6917 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6916 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6916 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6916 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6915 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6915 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6914 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6914 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6913 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6913 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6913 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6912 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6912 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6912 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6911 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6911 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6911 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6910 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6910 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6910 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6909 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6909 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6909 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6908 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6908 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6908 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6908 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6907 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6907 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6907 - val_accuracy: 0.5181 - val_loss: 0.6924\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6924\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6923\n",
      "Epoch 59/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6923\n",
      "Epoch 60/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6923\n",
      "Epoch 61/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6905 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 62/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6905 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 63/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6905 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 64/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6905 - val_accuracy: 0.5221 - val_loss: 0.6923\n",
      "Epoch 65/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6904 - val_accuracy: 0.5221 - val_loss: 0.6923\n",
      "Epoch 66/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6904 - val_accuracy: 0.5261 - val_loss: 0.6923\n",
      "Epoch 67/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6904 - val_accuracy: 0.5261 - val_loss: 0.6922\n",
      "Epoch 68/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6904 - val_accuracy: 0.5321 - val_loss: 0.6922\n",
      "Epoch 69/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6903 - val_accuracy: 0.5321 - val_loss: 0.6922\n",
      "Epoch 70/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6903 - val_accuracy: 0.5281 - val_loss: 0.6922\n",
      "Epoch 71/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6903 - val_accuracy: 0.5261 - val_loss: 0.6922\n",
      "Epoch 72/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6903 - val_accuracy: 0.5281 - val_loss: 0.6922\n",
      "Epoch 73/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5281 - val_loss: 0.6922\n",
      "Epoch 74/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5301 - val_loss: 0.6922\n",
      "Epoch 75/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6922\n",
      "Epoch 76/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 77/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 78/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.5141 - val_loss: 0.6921\n",
      "Epoch 79/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6901 - val_accuracy: 0.5161 - val_loss: 0.6921\n",
      "Epoch 80/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6901 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 81/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6901 - val_accuracy: 0.5141 - val_loss: 0.6921\n",
      "Epoch 82/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6901 - val_accuracy: 0.5141 - val_loss: 0.6921\n",
      "Epoch 83/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6901 - val_accuracy: 0.5141 - val_loss: 0.6920\n",
      "Epoch 84/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6900 - val_accuracy: 0.5120 - val_loss: 0.6920\n",
      "Epoch 85/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6900 - val_accuracy: 0.5120 - val_loss: 0.6920\n",
      "Epoch 86/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6900 - val_accuracy: 0.5161 - val_loss: 0.6920\n",
      "Epoch 87/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6900 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 88/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5141 - val_loss: 0.6920\n",
      "Epoch 89/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 90/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 91/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 92/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 93/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 94/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6898 - val_accuracy: 0.5080 - val_loss: 0.6919\n",
      "Epoch 95/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6898 - val_accuracy: 0.5181 - val_loss: 0.6918\n",
      "Epoch 96/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6898 - val_accuracy: 0.5060 - val_loss: 0.6918\n",
      "Epoch 97/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6898 - val_accuracy: 0.5141 - val_loss: 0.6918\n",
      "Epoch 98/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6898 - val_accuracy: 0.5161 - val_loss: 0.6918\n",
      "Epoch 99/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6897 - val_accuracy: 0.5100 - val_loss: 0.6918\n",
      "Epoch 100/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6897 - val_accuracy: 0.5201 - val_loss: 0.6917\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "AAPL - Accuracy: 0.5201, Precision: 0.5221, Recall: 0.8288, F1 Score: 0.6406\n",
      "Processing BA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  13.771849\n",
      "2023-12-26  13.461206\n",
      "2023-12-27  13.009378\n",
      "2023-12-28  12.367526\n",
      "2023-12-29  11.748438\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  273.481962  215.949037\n",
      "2023-12-26  274.179991  219.600008\n",
      "2023-12-27  274.469109  223.283891\n",
      "2023-12-28  274.100712  227.244289\n",
      "2023-12-29  274.212016  230.035985\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  72.628640\n",
      "2023-12-26  73.404074\n",
      "2023-12-27  72.777817\n",
      "2023-12-28  71.184406\n",
      "2023-12-29  71.299556\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  30.152536\n",
      "2023-12-26  30.814255\n",
      "2023-12-27  31.473025\n",
      "2023-12-28  31.905504\n",
      "2023-12-29  32.326469\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    233.407000    210.323667\n",
      "2023-12-26    235.611667    211.508834\n",
      "2023-12-27    237.530334    212.746667\n",
      "2023-12-28    239.293001    213.937167\n",
      "2023-12-29    241.024667    215.169334\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4913 - loss: 0.6938 - val_accuracy: 0.4739 - val_loss: 0.6942\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4893 - loss: 0.6933 - val_accuracy: 0.4799 - val_loss: 0.6935\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5305 - loss: 0.6928 - val_accuracy: 0.5020 - val_loss: 0.6928\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5283 - loss: 0.6925 - val_accuracy: 0.5141 - val_loss: 0.6927\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 0.6923 - val_accuracy: 0.5221 - val_loss: 0.6924\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 0.6922 - val_accuracy: 0.5542 - val_loss: 0.6921\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5225 - loss: 0.6921 - val_accuracy: 0.5462 - val_loss: 0.6919\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5221 - loss: 0.6921 - val_accuracy: 0.5442 - val_loss: 0.6918\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5234 - loss: 0.6921 - val_accuracy: 0.5522 - val_loss: 0.6917\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5212 - loss: 0.6922 - val_accuracy: 0.5301 - val_loss: 0.6914\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5215 - loss: 0.6922 - val_accuracy: 0.5241 - val_loss: 0.6913\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6912\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5234 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6912\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6912\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5210 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6911\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6910\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5238 - loss: 0.6921 - val_accuracy: 0.5141 - val_loss: 0.6911\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5225 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5233 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6911\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5221 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6911\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5251 - loss: 0.6922 - val_accuracy: 0.5161 - val_loss: 0.6910\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 0.6922 - val_accuracy: 0.5141 - val_loss: 0.6910\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5223 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5246 - loss: 0.6920 - val_accuracy: 0.5201 - val_loss: 0.6911\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5237 - loss: 0.6920 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.6920 - val_accuracy: 0.5120 - val_loss: 0.6910\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 0.6922 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.5161 - val_loss: 0.6909\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5218 - loss: 0.6923 - val_accuracy: 0.5201 - val_loss: 0.6909\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5244 - loss: 0.6923 - val_accuracy: 0.5120 - val_loss: 0.6909\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5229 - loss: 0.6922 - val_accuracy: 0.5181 - val_loss: 0.6909\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6910\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6909\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6910\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5229 - loss: 0.6920 - val_accuracy: 0.5201 - val_loss: 0.6910\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5232 - loss: 0.6921 - val_accuracy: 0.5161 - val_loss: 0.6910\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5233 - loss: 0.6920 - val_accuracy: 0.5161 - val_loss: 0.6910\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "BA - Accuracy: 0.5161, Precision: 0.5222, Recall: 0.9427, F1 Score: 0.6721\n",
      "Processing CAT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  10.809041\n",
      "2023-12-26  11.290983\n",
      "2023-12-27  11.736098\n",
      "2023-12-28  11.853386\n",
      "2023-12-29  11.714856\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  296.327808  231.593239\n",
      "2023-12-26  299.591099  233.094857\n",
      "2023-12-27  302.650403  235.035544\n",
      "2023-12-28  304.938676  237.432171\n",
      "2023-12-29  306.508654  240.302132\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  65.708420\n",
      "2023-12-26  67.585824\n",
      "2023-12-27  68.430600\n",
      "2023-12-28  67.524015\n",
      "2023-12-29  66.632900\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.549861\n",
      "2023-12-26  19.273801\n",
      "2023-12-27  20.018815\n",
      "2023-12-28  20.740104\n",
      "2023-12-29  21.284392\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    257.456844    253.669566\n",
      "2023-12-26    259.298999    254.065215\n",
      "2023-12-27    261.157616    254.522820\n",
      "2023-12-28    262.771600    255.005051\n",
      "2023-12-29    264.239398    255.531891\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4950 - loss: 0.6934 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6933 - val_accuracy: 0.5201 - val_loss: 0.6926\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6933 - val_accuracy: 0.5201 - val_loss: 0.6926\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6933 - val_accuracy: 0.5201 - val_loss: 0.6926\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6933 - val_accuracy: 0.5201 - val_loss: 0.6926\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 0.6932 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 0.6931 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 0.6931 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 0.6931 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: 0.6931 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5027 - loss: 0.6930 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.6930 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5012 - loss: 0.6929 - val_accuracy: 0.5201 - val_loss: 0.6925\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4971 - loss: 0.6929 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4969 - loss: 0.6928 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4971 - loss: 0.6928 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5018 - loss: 0.6928 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5073 - loss: 0.6927 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5108 - loss: 0.6927 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5102 - loss: 0.6926 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.6926 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6925 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6925 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5283 - loss: 0.6924 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 0.6923 - val_accuracy: 0.5201 - val_loss: 0.6924\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5309 - loss: 0.6923 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6922 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5337 - loss: 0.6922 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5358 - loss: 0.6921 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5316 - loss: 0.6920 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5383 - loss: 0.6919 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5407 - loss: 0.6919 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5340 - loss: 0.6919 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5406 - loss: 0.6918 - val_accuracy: 0.5201 - val_loss: 0.6923\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5382 - loss: 0.6917 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5242 - loss: 0.6917 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5408 - loss: 0.6916 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 0.6916 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5295 - loss: 0.6915 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5232 - loss: 0.6915 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5209 - loss: 0.6914 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5211 - loss: 0.6914 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5213 - loss: 0.6913 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5212 - loss: 0.6913 - val_accuracy: 0.5201 - val_loss: 0.6922\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5213 - loss: 0.6912 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5192 - loss: 0.6912 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.6911 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5172 - loss: 0.6911 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.6910 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5186 - loss: 0.6910 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 0.6909 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.6909 - val_accuracy: 0.5201 - val_loss: 0.6921\n",
      "Epoch 59/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5174 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 60/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5162 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 61/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6921\n",
      "Epoch 62/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5193 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 63/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.6907 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 64/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6907 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 65/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 66/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 67/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5172 - loss: 0.6906 - val_accuracy: 0.5161 - val_loss: 0.6920\n",
      "Epoch 68/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5127 - loss: 0.6905 - val_accuracy: 0.5161 - val_loss: 0.6920\n",
      "Epoch 69/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5142 - loss: 0.6905 - val_accuracy: 0.5161 - val_loss: 0.6920\n",
      "Epoch 70/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.6905 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 71/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6904 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 72/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5142 - loss: 0.6904 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 73/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5140 - loss: 0.6903 - val_accuracy: 0.5181 - val_loss: 0.6920\n",
      "Epoch 74/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.6903 - val_accuracy: 0.5201 - val_loss: 0.6920\n",
      "Epoch 75/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6920\n",
      "Epoch 76/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 77/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6901 - val_accuracy: 0.5241 - val_loss: 0.6919\n",
      "Epoch 78/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 79/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6901 - val_accuracy: 0.5221 - val_loss: 0.6920\n",
      "Epoch 80/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5151 - loss: 0.6901 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 81/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.6900 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 82/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6900 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 83/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.6900 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 84/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.6899 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 85/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5149 - loss: 0.6899 - val_accuracy: 0.5161 - val_loss: 0.6919\n",
      "Epoch 86/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 0.6898 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 87/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5153 - loss: 0.6898 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 88/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5146 - loss: 0.6898 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 89/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6897 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 90/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5149 - loss: 0.6898 - val_accuracy: 0.5221 - val_loss: 0.6919\n",
      "Epoch 91/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5149 - loss: 0.6897 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 92/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5142 - loss: 0.6897 - val_accuracy: 0.5120 - val_loss: 0.6919\n",
      "Epoch 93/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6896 - val_accuracy: 0.5161 - val_loss: 0.6919\n",
      "Epoch 94/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.6896 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 95/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.6895 - val_accuracy: 0.5100 - val_loss: 0.6919\n",
      "Epoch 96/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.6896 - val_accuracy: 0.5100 - val_loss: 0.6919\n",
      "Epoch 97/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6895 - val_accuracy: 0.5120 - val_loss: 0.6919\n",
      "Epoch 98/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.6895 - val_accuracy: 0.5181 - val_loss: 0.6919\n",
      "Epoch 99/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5164 - loss: 0.6894 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "Epoch 100/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6894 - val_accuracy: 0.5201 - val_loss: 0.6919\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "CAT - Accuracy: 0.5201, Precision: 0.5233, Recall: 0.8687, F1 Score: 0.6531\n",
      "Processing CVX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.051432\n",
      "2023-12-26  1.283365\n",
      "2023-12-27  1.411392\n",
      "2023-12-28  1.328433\n",
      "2023-12-29  1.200642\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  149.447753  136.831083\n",
      "2023-12-26  150.318657  136.748529\n",
      "2023-12-27  150.982147  136.711803\n",
      "2023-12-28  151.238857  137.028973\n",
      "2023-12-29  151.369041  137.443288\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  51.680810\n",
      "2023-12-26  53.209339\n",
      "2023-12-27  52.576787\n",
      "2023-12-28  49.947765\n",
      "2023-12-29  49.221978\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  19.168902\n",
      "2023-12-26  18.560335\n",
      "2023-12-27  17.957627\n",
      "2023-12-28  17.531170\n",
      "2023-12-29  17.175811\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    142.284917    147.527762\n",
      "2023-12-26    142.642137    147.291734\n",
      "2023-12-27    142.949114    147.081143\n",
      "2023-12-28    143.152314    146.829323\n",
      "2023-12-29    143.319124    146.630380\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4901 - loss: 0.6935 - val_accuracy: 0.5281 - val_loss: 0.6923\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5021 - loss: 0.6936 - val_accuracy: 0.5281 - val_loss: 0.6924\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5065 - loss: 0.6936 - val_accuracy: 0.5281 - val_loss: 0.6925\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 0.6936 - val_accuracy: 0.5281 - val_loss: 0.6925\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5075 - loss: 0.6936 - val_accuracy: 0.5281 - val_loss: 0.6925\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5056 - loss: 0.6935 - val_accuracy: 0.5281 - val_loss: 0.6926\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5044 - loss: 0.6935 - val_accuracy: 0.5281 - val_loss: 0.6927\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: 0.6935 - val_accuracy: 0.5281 - val_loss: 0.6927\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5058 - loss: 0.6935 - val_accuracy: 0.5281 - val_loss: 0.6928\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: 0.6934 - val_accuracy: 0.5281 - val_loss: 0.6928\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 0.6934 - val_accuracy: 0.5281 - val_loss: 0.6928\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "CVX - Accuracy: 0.5281, Precision: 0.5281, Recall: 1.0000, F1 Score: 0.6912\n",
      "Processing CSCO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -0.079737\n",
      "2023-12-26 -0.020302\n",
      "2023-12-27  0.038951\n",
      "2023-12-28  0.088044\n",
      "2023-12-29  0.128619\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  49.477523  46.034496\n",
      "2023-12-26  49.620491  46.120859\n",
      "2023-12-27  49.754252  46.239851\n",
      "2023-12-28  49.878277  46.352964\n",
      "2023-12-29  50.003730  46.436349\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  47.654651\n",
      "2023-12-26  48.451977\n",
      "2023-12-27  49.127018\n",
      "2023-12-28  49.298735\n",
      "2023-12-29  49.475174\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.759063\n",
      "2023-12-26  22.472070\n",
      "2023-12-27  22.138082\n",
      "2023-12-28  21.790178\n",
      "2023-12-29  21.510879\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     48.088296     49.934079\n",
      "2023-12-26     48.013153     49.883748\n",
      "2023-12-27     47.954926     49.825845\n",
      "2023-12-28     47.867422     49.774287\n",
      "2023-12-29     47.777642     49.726631\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4899 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 59/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 60/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 61/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "CSCO - Accuracy: 0.5000, Precision: 0.5000, Recall: 1.0000, F1 Score: 0.6667\n",
      "Processing KO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.350238\n",
      "2023-12-26  0.329580\n",
      "2023-12-27  0.321419\n",
      "2023-12-28  0.314503\n",
      "2023-12-29  0.319636\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  58.747124  56.622262\n",
      "2023-12-26  58.740163  56.684529\n",
      "2023-12-27  58.743695  56.739350\n",
      "2023-12-28  58.708991  56.870528\n",
      "2023-12-29  58.729875  56.897881\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  53.559845\n",
      "2023-12-26  54.557063\n",
      "2023-12-27  55.179309\n",
      "2023-12-28  55.348006\n",
      "2023-12-29  56.116763\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  11.417479\n",
      "2023-12-26  11.047345\n",
      "2023-12-27  10.689212\n",
      "2023-12-28  10.377879\n",
      "2023-12-29  10.115714\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     57.168742     55.464373\n",
      "2023-12-26     57.243824     55.513958\n",
      "2023-12-27     57.316990     55.574144\n",
      "2023-12-28     57.385935     55.644753\n",
      "2023-12-29     57.457206     55.715710\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5296 - loss: 0.6930 - val_accuracy: 0.5301 - val_loss: 0.6915\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6925 - val_accuracy: 0.5301 - val_loss: 0.6917\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6924 - val_accuracy: 0.5301 - val_loss: 0.6918\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6923 - val_accuracy: 0.5301 - val_loss: 0.6919\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6923 - val_accuracy: 0.5301 - val_loss: 0.6921\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6922 - val_accuracy: 0.5301 - val_loss: 0.6922\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6922 - val_accuracy: 0.5301 - val_loss: 0.6922\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6921 - val_accuracy: 0.5301 - val_loss: 0.6923\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6921 - val_accuracy: 0.5301 - val_loss: 0.6925\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6921 - val_accuracy: 0.5301 - val_loss: 0.6927\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.6920 - val_accuracy: 0.5301 - val_loss: 0.6927\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "KO - Accuracy: 0.5301, Precision: 0.5301, Recall: 1.0000, F1 Score: 0.6929\n",
      "Processing DIS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.711233\n",
      "2023-12-26  0.555955\n",
      "2023-12-27  0.382701\n",
      "2023-12-28  0.244188\n",
      "2023-12-29  0.124148\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  94.064274  89.768311\n",
      "2023-12-26  93.615433  89.827864\n",
      "2023-12-27  93.673203  89.588977\n",
      "2023-12-28  93.703923  89.379133\n",
      "2023-12-29  93.706805  89.167323\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  52.804370\n",
      "2023-12-26  52.683228\n",
      "2023-12-27  51.684420\n",
      "2023-12-28  51.717654\n",
      "2023-12-29  51.516083\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  17.776530\n",
      "2023-12-26  17.577500\n",
      "2023-12-27  17.297793\n",
      "2023-12-28  17.016418\n",
      "2023-12-29  16.726693\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     92.100409     87.251392\n",
      "2023-12-26     92.198846     87.420002\n",
      "2023-12-27     92.239676     87.568904\n",
      "2023-12-28     92.227261     87.753359\n",
      "2023-12-29     92.116609     87.939628\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5384 - loss: 0.6923 - val_accuracy: 0.4679 - val_loss: 0.6939\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5384 - loss: 0.6924 - val_accuracy: 0.4719 - val_loss: 0.6938\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5385 - loss: 0.6920 - val_accuracy: 0.4679 - val_loss: 0.6939\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 0.6916 - val_accuracy: 0.4900 - val_loss: 0.6939\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5380 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6943\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5382 - loss: 0.6909 - val_accuracy: 0.4839 - val_loss: 0.6945\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5382 - loss: 0.6907 - val_accuracy: 0.4779 - val_loss: 0.6946\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5382 - loss: 0.6905 - val_accuracy: 0.4759 - val_loss: 0.6948\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5391 - loss: 0.6903 - val_accuracy: 0.4779 - val_loss: 0.6950\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 0.6902 - val_accuracy: 0.4759 - val_loss: 0.6951\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5382 - loss: 0.6901 - val_accuracy: 0.4799 - val_loss: 0.6951\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5386 - loss: 0.6900 - val_accuracy: 0.4839 - val_loss: 0.6952\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "DIS - Accuracy: 0.4719, Precision: 0.4696, Recall: 0.9957, F1 Score: 0.6382\n",
      "Processing DOW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (1205, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.233266\n",
      "2023-12-26  1.302879\n",
      "2023-12-27  1.342572\n",
      "2023-12-28  1.321017\n",
      "2023-12-29  1.258726\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  54.411207  47.984420\n",
      "2023-12-26  54.807861  48.103061\n",
      "2023-12-27  55.165621  48.205744\n",
      "2023-12-28  55.398142  48.353673\n",
      "2023-12-29  55.555490  48.497759\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.984922\n",
      "2023-12-26  64.447043\n",
      "2023-12-27  64.447043\n",
      "2023-12-28  62.304359\n",
      "2023-12-29  60.610600\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  12.951968\n",
      "2023-12-26  13.466117\n",
      "2023-12-27  13.963128\n",
      "2023-12-28  14.335276\n",
      "2023-12-29  14.532532\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     50.520550     49.106964\n",
      "2023-12-26     50.744921     49.185790\n",
      "2023-12-27     50.976989     49.268785\n",
      "2023-12-28     51.135391     49.348467\n",
      "2023-12-29     51.265715     49.420365\n",
      "After dropping NaN values: (1176, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5281 - loss: 0.6928 - val_accuracy: 0.5085 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5281 - loss: 0.6930 - val_accuracy: 0.4576 - val_loss: 0.6933\n",
      "Epoch 3/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 4/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: 0.6929 - val_accuracy: 0.4915 - val_loss: 0.6933\n",
      "Epoch 5/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5139 - loss: 0.6927 - val_accuracy: 0.4915 - val_loss: 0.6933\n",
      "Epoch 6/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5225 - loss: 0.6926 - val_accuracy: 0.4915 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5212 - loss: 0.6924 - val_accuracy: 0.4915 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5299 - loss: 0.6921 - val_accuracy: 0.4915 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6919 - val_accuracy: 0.4915 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6918 - val_accuracy: 0.4915 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5295 - loss: 0.6916 - val_accuracy: 0.4915 - val_loss: 0.6931\n",
      "Epoch 12/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6914 - val_accuracy: 0.4915 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 0.6913 - val_accuracy: 0.4915 - val_loss: 0.6931\n",
      "Epoch 14/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5266 - loss: 0.6911 - val_accuracy: 0.4915 - val_loss: 0.6930\n",
      "Epoch 15/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6910 - val_accuracy: 0.4915 - val_loss: 0.6930\n",
      "Epoch 16/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5318 - loss: 0.6909 - val_accuracy: 0.4915 - val_loss: 0.6930\n",
      "Epoch 17/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.6908 - val_accuracy: 0.4915 - val_loss: 0.6930\n",
      "Epoch 18/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 0.6907 - val_accuracy: 0.4915 - val_loss: 0.6929\n",
      "Epoch 19/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5295 - loss: 0.6906 - val_accuracy: 0.4915 - val_loss: 0.6929\n",
      "Epoch 20/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 0.6905 - val_accuracy: 0.4915 - val_loss: 0.6928\n",
      "Epoch 21/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5303 - loss: 0.6904 - val_accuracy: 0.4915 - val_loss: 0.6928\n",
      "Epoch 22/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6903 - val_accuracy: 0.4915 - val_loss: 0.6928\n",
      "Epoch 23/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 0.6903 - val_accuracy: 0.4915 - val_loss: 0.6927\n",
      "Epoch 24/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5312 - loss: 0.6902 - val_accuracy: 0.4915 - val_loss: 0.6927\n",
      "Epoch 25/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5319 - loss: 0.6901 - val_accuracy: 0.4915 - val_loss: 0.6927\n",
      "Epoch 26/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 0.6901 - val_accuracy: 0.4915 - val_loss: 0.6926\n",
      "Epoch 27/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5320 - loss: 0.6900 - val_accuracy: 0.4915 - val_loss: 0.6926\n",
      "Epoch 28/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5341 - loss: 0.6900 - val_accuracy: 0.4915 - val_loss: 0.6926\n",
      "Epoch 29/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 0.6899 - val_accuracy: 0.4915 - val_loss: 0.6925\n",
      "Epoch 30/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5370 - loss: 0.6898 - val_accuracy: 0.4915 - val_loss: 0.6925\n",
      "Epoch 31/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5348 - loss: 0.6898 - val_accuracy: 0.4958 - val_loss: 0.6924\n",
      "Epoch 32/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6897 - val_accuracy: 0.4958 - val_loss: 0.6924\n",
      "Epoch 33/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 0.6897 - val_accuracy: 0.5042 - val_loss: 0.6924\n",
      "Epoch 34/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5338 - loss: 0.6896 - val_accuracy: 0.5042 - val_loss: 0.6923\n",
      "Epoch 35/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 0.6896 - val_accuracy: 0.5042 - val_loss: 0.6923\n",
      "Epoch 36/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5345 - loss: 0.6895 - val_accuracy: 0.5042 - val_loss: 0.6923\n",
      "Epoch 37/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5348 - loss: 0.6895 - val_accuracy: 0.5042 - val_loss: 0.6923\n",
      "Epoch 38/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5340 - loss: 0.6894 - val_accuracy: 0.5042 - val_loss: 0.6922\n",
      "Epoch 39/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5335 - loss: 0.6894 - val_accuracy: 0.5042 - val_loss: 0.6922\n",
      "Epoch 40/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.6893 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
      "Epoch 41/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.6893 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
      "Epoch 42/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.6892 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
      "Epoch 43/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.6892 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
      "Epoch 44/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6891 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
      "Epoch 45/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5336 - loss: 0.6891 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
      "Epoch 46/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5342 - loss: 0.6891 - val_accuracy: 0.5042 - val_loss: 0.6920\n",
      "Epoch 47/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6890 - val_accuracy: 0.5042 - val_loss: 0.6920\n",
      "Epoch 48/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5342 - loss: 0.6889 - val_accuracy: 0.5042 - val_loss: 0.6920\n",
      "Epoch 49/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 0.6889 - val_accuracy: 0.5085 - val_loss: 0.6919\n",
      "Epoch 50/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.6888 - val_accuracy: 0.5042 - val_loss: 0.6920\n",
      "Epoch 51/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5334 - loss: 0.6888 - val_accuracy: 0.5085 - val_loss: 0.6919\n",
      "Epoch 52/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5342 - loss: 0.6888 - val_accuracy: 0.5085 - val_loss: 0.6919\n",
      "Epoch 53/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5352 - loss: 0.6887 - val_accuracy: 0.5085 - val_loss: 0.6919\n",
      "Epoch 54/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6886 - val_accuracy: 0.5085 - val_loss: 0.6919\n",
      "Epoch 55/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 0.6886 - val_accuracy: 0.5127 - val_loss: 0.6918\n",
      "Epoch 56/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6885 - val_accuracy: 0.5085 - val_loss: 0.6918\n",
      "Epoch 57/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5348 - loss: 0.6885 - val_accuracy: 0.5085 - val_loss: 0.6918\n",
      "Epoch 58/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5348 - loss: 0.6884 - val_accuracy: 0.5085 - val_loss: 0.6918\n",
      "Epoch 59/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 0.6884 - val_accuracy: 0.5127 - val_loss: 0.6917\n",
      "Epoch 60/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 0.6884 - val_accuracy: 0.5127 - val_loss: 0.6917\n",
      "Epoch 61/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5334 - loss: 0.6883 - val_accuracy: 0.5127 - val_loss: 0.6917\n",
      "Epoch 62/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 0.6883 - val_accuracy: 0.5127 - val_loss: 0.6917\n",
      "Epoch 63/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.6882 - val_accuracy: 0.5127 - val_loss: 0.6916\n",
      "Epoch 64/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5331 - loss: 0.6882 - val_accuracy: 0.5169 - val_loss: 0.6916\n",
      "Epoch 65/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 0.6882 - val_accuracy: 0.5127 - val_loss: 0.6916\n",
      "Epoch 66/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.6881 - val_accuracy: 0.5169 - val_loss: 0.6916\n",
      "Epoch 67/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6880 - val_accuracy: 0.5169 - val_loss: 0.6915\n",
      "Epoch 68/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6880 - val_accuracy: 0.5169 - val_loss: 0.6915\n",
      "Epoch 69/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6879 - val_accuracy: 0.5254 - val_loss: 0.6915\n",
      "Epoch 70/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 0.6879 - val_accuracy: 0.5254 - val_loss: 0.6915\n",
      "Epoch 71/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5360 - loss: 0.6878 - val_accuracy: 0.5254 - val_loss: 0.6915\n",
      "Epoch 72/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5347 - loss: 0.6878 - val_accuracy: 0.5169 - val_loss: 0.6914\n",
      "Epoch 73/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6876 - val_accuracy: 0.5169 - val_loss: 0.6914\n",
      "Epoch 74/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5394 - loss: 0.6876 - val_accuracy: 0.5169 - val_loss: 0.6914\n",
      "Epoch 75/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 0.6875 - val_accuracy: 0.5212 - val_loss: 0.6913\n",
      "Epoch 76/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5426 - loss: 0.6875 - val_accuracy: 0.5212 - val_loss: 0.6913\n",
      "Epoch 77/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5441 - loss: 0.6875 - val_accuracy: 0.5212 - val_loss: 0.6913\n",
      "Epoch 78/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5391 - loss: 0.6874 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 79/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5406 - loss: 0.6874 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 80/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5377 - loss: 0.6872 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 81/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5402 - loss: 0.6873 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 82/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5425 - loss: 0.6872 - val_accuracy: 0.5297 - val_loss: 0.6912\n",
      "Epoch 83/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5421 - loss: 0.6871 - val_accuracy: 0.5254 - val_loss: 0.6912\n",
      "Epoch 84/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5433 - loss: 0.6870 - val_accuracy: 0.5297 - val_loss: 0.6911\n",
      "Epoch 85/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5430 - loss: 0.6870 - val_accuracy: 0.5297 - val_loss: 0.6911\n",
      "Epoch 86/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5466 - loss: 0.6870 - val_accuracy: 0.5297 - val_loss: 0.6911\n",
      "Epoch 87/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5471 - loss: 0.6869 - val_accuracy: 0.5297 - val_loss: 0.6911\n",
      "Epoch 88/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5506 - loss: 0.6869 - val_accuracy: 0.5297 - val_loss: 0.6910\n",
      "Epoch 89/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 0.6867 - val_accuracy: 0.5297 - val_loss: 0.6910\n",
      "Epoch 90/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5496 - loss: 0.6866 - val_accuracy: 0.5297 - val_loss: 0.6910\n",
      "Epoch 91/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5508 - loss: 0.6867 - val_accuracy: 0.5381 - val_loss: 0.6910\n",
      "Epoch 92/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5508 - loss: 0.6866 - val_accuracy: 0.5297 - val_loss: 0.6909\n",
      "Epoch 93/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5468 - loss: 0.6865 - val_accuracy: 0.5297 - val_loss: 0.6909\n",
      "Epoch 94/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5464 - loss: 0.6864 - val_accuracy: 0.5254 - val_loss: 0.6909\n",
      "Epoch 95/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5509 - loss: 0.6865 - val_accuracy: 0.5212 - val_loss: 0.6908\n",
      "Epoch 96/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5502 - loss: 0.6864 - val_accuracy: 0.5339 - val_loss: 0.6908\n",
      "Epoch 97/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5506 - loss: 0.6864 - val_accuracy: 0.5254 - val_loss: 0.6908\n",
      "Epoch 98/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5497 - loss: 0.6863 - val_accuracy: 0.5339 - val_loss: 0.6908\n",
      "Epoch 99/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5446 - loss: 0.6862 - val_accuracy: 0.5339 - val_loss: 0.6907\n",
      "Epoch 100/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5488 - loss: 0.6862 - val_accuracy: 0.5339 - val_loss: 0.6907\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "DOW - Accuracy: 0.5339, Precision: 0.6471, Recall: 0.1833, F1 Score: 0.2857\n",
      "Processing GS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  13.885094\n",
      "2023-12-26  13.771040\n",
      "2023-12-27  13.750715\n",
      "2023-12-28  13.730045\n",
      "2023-12-29  13.506993\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  387.832499  318.588055\n",
      "2023-12-26  389.937889  321.087023\n",
      "2023-12-27  391.890607  324.027805\n",
      "2023-12-28  394.036332  326.437041\n",
      "2023-12-29  395.592248  329.246582\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  67.636859\n",
      "2023-12-26  67.906394\n",
      "2023-12-27  68.712282\n",
      "2023-12-28  69.249449\n",
      "2023-12-29  68.843987\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.338823\n",
      "2023-12-26  23.033414\n",
      "2023-12-27  23.769566\n",
      "2023-12-28  24.521653\n",
      "2023-12-29  25.245340\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    345.012025    324.121336\n",
      "2023-12-26    346.944917    325.119435\n",
      "2023-12-27    348.926547    326.247467\n",
      "2023-12-28    350.586294    327.609238\n",
      "2023-12-29    352.261532    328.920016\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 0.6927 - val_accuracy: 0.5040 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5247 - loss: 0.6921 - val_accuracy: 0.5100 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5240 - loss: 0.6918 - val_accuracy: 0.5201 - val_loss: 0.6931\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6916 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6915 - val_accuracy: 0.5040 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6914 - val_accuracy: 0.4980 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6913 - val_accuracy: 0.4960 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6912 - val_accuracy: 0.4980 - val_loss: 0.6933\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5240 - loss: 0.6912 - val_accuracy: 0.4960 - val_loss: 0.6933\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5240 - loss: 0.6912 - val_accuracy: 0.4980 - val_loss: 0.6934\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5242 - loss: 0.6912 - val_accuracy: 0.4960 - val_loss: 0.6934\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 0.6911 - val_accuracy: 0.4960 - val_loss: 0.6934\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5240 - loss: 0.6911 - val_accuracy: 0.4960 - val_loss: 0.6935\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000260E980B740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "GS - Accuracy: 0.5201, Precision: 0.5600, Recall: 0.2231, F1 Score: 0.3191\n",
      "Processing HD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  12.444255\n",
      "2023-12-26  12.060427\n",
      "2023-12-27  11.560841\n",
      "2023-12-28  10.945541\n",
      "2023-12-29  10.274945\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  358.784178  298.027807\n",
      "2023-12-26  359.562672  301.243871\n",
      "2023-12-27  359.937631  304.549164\n",
      "2023-12-28  359.527947  308.546302\n",
      "2023-12-29  358.723402  312.614504\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  68.807103\n",
      "2023-12-26  69.072377\n",
      "2023-12-27  68.420283\n",
      "2023-12-28  67.432436\n",
      "2023-12-29  66.742323\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  26.809036\n",
      "2023-12-26  27.334479\n",
      "2023-12-27  27.779480\n",
      "2023-12-28  28.120907\n",
      "2023-12-29  28.276407\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    318.260429    301.725882\n",
      "2023-12-26    320.223787    302.534811\n",
      "2023-12-27    322.276536    303.368987\n",
      "2023-12-28    323.782176    304.312862\n",
      "2023-12-29    325.112108    305.236054\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5339 - loss: 0.6921 - val_accuracy: 0.5120 - val_loss: 0.6983\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6906 - val_accuracy: 0.5120 - val_loss: 0.7003\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6904 - val_accuracy: 0.5120 - val_loss: 0.7010\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6903 - val_accuracy: 0.5120 - val_loss: 0.7014\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6902 - val_accuracy: 0.5120 - val_loss: 0.7018\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6901 - val_accuracy: 0.5120 - val_loss: 0.7020\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6900 - val_accuracy: 0.5120 - val_loss: 0.7022\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6899 - val_accuracy: 0.5120 - val_loss: 0.7025\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6898 - val_accuracy: 0.5120 - val_loss: 0.7027\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5394 - loss: 0.6898 - val_accuracy: 0.5120 - val_loss: 0.7029\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5394 - loss: 0.6897 - val_accuracy: 0.5120 - val_loss: 0.7030\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "HD - Accuracy: 0.5120, Precision: 0.5120, Recall: 1.0000, F1 Score: 0.6773\n",
      "Processing HON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.978789\n",
      "2023-12-26  4.128490\n",
      "2023-12-27  4.276070\n",
      "2023-12-28  4.354802\n",
      "2023-12-29  4.409475\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  205.744468  189.556315\n",
      "2023-12-26  206.612606  190.179046\n",
      "2023-12-27  207.596115  190.654749\n",
      "2023-12-28  208.355054  191.370849\n",
      "2023-12-29  209.177382  191.912761\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  64.398526\n",
      "2023-12-26  66.332043\n",
      "2023-12-27  67.087120\n",
      "2023-12-28  67.203567\n",
      "2023-12-29  67.630134\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  16.200170\n",
      "2023-12-26  16.658072\n",
      "2023-12-27  17.171945\n",
      "2023-12-28  17.688467\n",
      "2023-12-29  18.200781\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    194.544005    187.461051\n",
      "2023-12-26    195.247394    187.863047\n",
      "2023-12-27    195.989696    188.316115\n",
      "2023-12-28    196.613941    188.795753\n",
      "2023-12-29    197.278748    189.262001\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5449 - loss: 0.6915 - val_accuracy: 0.5161 - val_loss: 0.6945\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6904 - val_accuracy: 0.5161 - val_loss: 0.6941\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6900 - val_accuracy: 0.5161 - val_loss: 0.6940\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6898 - val_accuracy: 0.5161 - val_loss: 0.6938\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6896 - val_accuracy: 0.5161 - val_loss: 0.6938\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6894 - val_accuracy: 0.5161 - val_loss: 0.6936\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6893 - val_accuracy: 0.5161 - val_loss: 0.6936\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6892 - val_accuracy: 0.5161 - val_loss: 0.6935\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6891 - val_accuracy: 0.5161 - val_loss: 0.6934\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6890 - val_accuracy: 0.5161 - val_loss: 0.6934\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6889 - val_accuracy: 0.5161 - val_loss: 0.6933\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6888 - val_accuracy: 0.5161 - val_loss: 0.6932\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6886 - val_accuracy: 0.5161 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6885 - val_accuracy: 0.5161 - val_loss: 0.6932\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6883 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6882 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6881 - val_accuracy: 0.5161 - val_loss: 0.6931\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6879 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6878 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5464 - loss: 0.6876 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.6875 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5449 - loss: 0.6874 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5470 - loss: 0.6872 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5466 - loss: 0.6871 - val_accuracy: 0.5161 - val_loss: 0.6929\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.6870 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.6868 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 0.6867 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 0.6866 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 0.6865 - val_accuracy: 0.5161 - val_loss: 0.6927\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5464 - loss: 0.6864 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 0.6862 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5531 - loss: 0.6861 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5541 - loss: 0.6860 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5537 - loss: 0.6859 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 0.6859 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5610 - loss: 0.6858 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5610 - loss: 0.6856 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 0.6857 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5577 - loss: 0.6856 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5611 - loss: 0.6854 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5578 - loss: 0.6854 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5574 - loss: 0.6853 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5605 - loss: 0.6852 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 0.6851 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5583 - loss: 0.6851 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5491 - loss: 0.6850 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5504 - loss: 0.6849 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5549 - loss: 0.6849 - val_accuracy: 0.5161 - val_loss: 0.6924\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.6848 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5511 - loss: 0.6848 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5494 - loss: 0.6847 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5514 - loss: 0.6846 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.6846 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5506 - loss: 0.6845 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5536 - loss: 0.6845 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.6844 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.6844 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 0.6843 - val_accuracy: 0.5161 - val_loss: 0.6925\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "HON - Accuracy: 0.5161, Precision: 0.5161, Recall: 1.0000, F1 Score: 0.6808\n",
      "Processing IBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.704118\n",
      "2023-12-26  2.651478\n",
      "2023-12-27  2.599419\n",
      "2023-12-28  2.551511\n",
      "2023-12-29  2.469380\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  161.261922  151.558160\n",
      "2023-12-26  161.131345  152.431893\n",
      "2023-12-27  160.841504  153.481426\n",
      "2023-12-28  160.500921  154.535983\n",
      "2023-12-29  160.405903  155.116388\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  65.720211\n",
      "2023-12-26  66.890119\n",
      "2023-12-27  67.161000\n",
      "2023-12-28  67.480248\n",
      "2023-12-29  67.015445\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  28.644801\n",
      "2023-12-26  28.812194\n",
      "2023-12-27  28.999145\n",
      "2023-12-28  29.204513\n",
      "2023-12-29  29.311333\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    153.707834    145.258489\n",
      "2023-12-26    154.167929    145.655411\n",
      "2023-12-27    154.665961    146.048372\n",
      "2023-12-28    155.098495    146.452606\n",
      "2023-12-29    155.454186    146.842697\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5074 - loss: 0.6932 - val_accuracy: 0.5361 - val_loss: 0.6917\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4985 - loss: 0.6935 - val_accuracy: 0.5361 - val_loss: 0.6919\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4990 - loss: 0.6934 - val_accuracy: 0.5201 - val_loss: 0.6927\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5071 - loss: 0.6931 - val_accuracy: 0.4880 - val_loss: 0.6939\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5005 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6952\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4997 - loss: 0.6926 - val_accuracy: 0.4558 - val_loss: 0.6968\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5030 - loss: 0.6924 - val_accuracy: 0.4759 - val_loss: 0.6986\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5087 - loss: 0.6921 - val_accuracy: 0.4659 - val_loss: 0.7006\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5173 - loss: 0.6920 - val_accuracy: 0.4578 - val_loss: 0.7029\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5233 - loss: 0.6918 - val_accuracy: 0.4639 - val_loss: 0.7049\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5254 - loss: 0.6917 - val_accuracy: 0.4639 - val_loss: 0.7069\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "IBM - Accuracy: 0.5361, Precision: 0.5361, Recall: 1.0000, F1 Score: 0.6980\n",
      "Processing INTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.671324\n",
      "2023-12-26  1.934359\n",
      "2023-12-27  2.138862\n",
      "2023-12-28  2.245586\n",
      "2023-12-29  2.292590\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  47.362069  40.438039\n",
      "2023-12-26  48.528518  39.905106\n",
      "2023-12-27  49.539717  39.538276\n",
      "2023-12-28  50.293103  39.322688\n",
      "2023-12-29  50.934575  39.228881\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  66.096401\n",
      "2023-12-26  69.625522\n",
      "2023-12-27  69.961913\n",
      "2023-12-28  68.839575\n",
      "2023-12-29  68.409991\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  25.610192\n",
      "2023-12-26  26.385538\n",
      "2023-12-27  27.200672\n",
      "2023-12-28  27.980741\n",
      "2023-12-29  28.631002\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     43.090891     39.303954\n",
      "2023-12-26     43.473763     39.551744\n",
      "2023-12-27     43.885910     39.805285\n",
      "2023-12-28     44.247073     40.048971\n",
      "2023-12-29     44.564160     40.286420\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5243 - loss: 0.6928 - val_accuracy: 0.4980 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.4980 - val_loss: 0.6933\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5265 - loss: 0.6920 - val_accuracy: 0.4980 - val_loss: 0.6933\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5269 - loss: 0.6917 - val_accuracy: 0.5020 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 0.6916 - val_accuracy: 0.4940 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6915 - val_accuracy: 0.4960 - val_loss: 0.6933\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5289 - loss: 0.6915 - val_accuracy: 0.5020 - val_loss: 0.6933\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.4960 - val_loss: 0.6933\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 0.6914 - val_accuracy: 0.5020 - val_loss: 0.6934\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5120 - val_loss: 0.6934\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6914 - val_accuracy: 0.5161 - val_loss: 0.6934\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.6913 - val_accuracy: 0.5161 - val_loss: 0.6934\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6913 - val_accuracy: 0.5181 - val_loss: 0.6934\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6913 - val_accuracy: 0.5201 - val_loss: 0.6934\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5308 - loss: 0.6912 - val_accuracy: 0.5241 - val_loss: 0.6935\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step\n",
      "INTC - Accuracy: 0.4940, Precision: 0.4959, Recall: 0.9677, F1 Score: 0.6557\n",
      "Processing JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.862656\n",
      "2023-12-26  0.879688\n",
      "2023-12-27  0.899501\n",
      "2023-12-28  0.922835\n",
      "2023-12-29  0.943167\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  156.900586  148.823097\n",
      "2023-12-26  156.727070  149.475085\n",
      "2023-12-27  156.519242  150.147601\n",
      "2023-12-28  156.296985  150.809934\n",
      "2023-12-29  156.351635  150.960062\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  51.865475\n",
      "2023-12-26  52.837202\n",
      "2023-12-27  53.139441\n",
      "2023-12-28  53.477198\n",
      "2023-12-29  53.717293\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.473561\n",
      "2023-12-26  18.300921\n",
      "2023-12-27  18.112726\n",
      "2023-12-28  17.840204\n",
      "2023-12-29  17.577808\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    150.755808    150.082421\n",
      "2023-12-26    151.085940    150.109123\n",
      "2023-12-27    151.410592    150.149038\n",
      "2023-12-28    151.741816    150.189634\n",
      "2023-12-29    152.041176    150.229926\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5072 - loss: 0.6929 - val_accuracy: 0.4839 - val_loss: 0.6977\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6924 - val_accuracy: 0.4839 - val_loss: 0.6974\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6972\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6921 - val_accuracy: 0.4839 - val_loss: 0.6970\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6961\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6961\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6960\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5271 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 0.6911 - val_accuracy: 0.4839 - val_loss: 0.6958\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 0.6911 - val_accuracy: 0.4839 - val_loss: 0.6958\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5242 - loss: 0.6910 - val_accuracy: 0.4839 - val_loss: 0.6957\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5242 - loss: 0.6910 - val_accuracy: 0.4839 - val_loss: 0.6956\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5242 - loss: 0.6909 - val_accuracy: 0.4839 - val_loss: 0.6956\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 0.6909 - val_accuracy: 0.4859 - val_loss: 0.6956\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5256 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6956\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6955\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5225 - loss: 0.6907 - val_accuracy: 0.4819 - val_loss: 0.6955\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5215 - loss: 0.6907 - val_accuracy: 0.4799 - val_loss: 0.6955\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.6907 - val_accuracy: 0.4819 - val_loss: 0.6954\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5207 - loss: 0.6906 - val_accuracy: 0.4859 - val_loss: 0.6954\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5223 - loss: 0.6906 - val_accuracy: 0.4839 - val_loss: 0.6954\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5234 - loss: 0.6905 - val_accuracy: 0.4859 - val_loss: 0.6953\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5238 - loss: 0.6905 - val_accuracy: 0.4880 - val_loss: 0.6954\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6904 - val_accuracy: 0.4859 - val_loss: 0.6954\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 0.6904 - val_accuracy: 0.4859 - val_loss: 0.6953\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5243 - loss: 0.6904 - val_accuracy: 0.4859 - val_loss: 0.6952\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5239 - loss: 0.6903 - val_accuracy: 0.4880 - val_loss: 0.6952\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.6903 - val_accuracy: 0.4880 - val_loss: 0.6951\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5225 - loss: 0.6903 - val_accuracy: 0.4880 - val_loss: 0.6952\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5236 - loss: 0.6902 - val_accuracy: 0.4839 - val_loss: 0.6952\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5236 - loss: 0.6902 - val_accuracy: 0.4859 - val_loss: 0.6951\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5250 - loss: 0.6902 - val_accuracy: 0.4859 - val_loss: 0.6952\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5263 - loss: 0.6901 - val_accuracy: 0.4859 - val_loss: 0.6951\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5271 - loss: 0.6901 - val_accuracy: 0.4859 - val_loss: 0.6951\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5266 - loss: 0.6900 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 0.6900 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
      "Epoch 45/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5286 - loss: 0.6900 - val_accuracy: 0.4880 - val_loss: 0.6951\n",
      "Epoch 46/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6899 - val_accuracy: 0.4880 - val_loss: 0.6950\n",
      "Epoch 47/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5286 - loss: 0.6899 - val_accuracy: 0.4880 - val_loss: 0.6950\n",
      "Epoch 48/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5280 - loss: 0.6899 - val_accuracy: 0.4880 - val_loss: 0.6949\n",
      "Epoch 49/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5317 - loss: 0.6898 - val_accuracy: 0.4880 - val_loss: 0.6949\n",
      "Epoch 50/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 0.6898 - val_accuracy: 0.4880 - val_loss: 0.6949\n",
      "Epoch 51/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6898 - val_accuracy: 0.4920 - val_loss: 0.6948\n",
      "Epoch 52/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5317 - loss: 0.6898 - val_accuracy: 0.4880 - val_loss: 0.6948\n",
      "Epoch 53/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6897 - val_accuracy: 0.4880 - val_loss: 0.6947\n",
      "Epoch 54/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5325 - loss: 0.6897 - val_accuracy: 0.4880 - val_loss: 0.6947\n",
      "Epoch 55/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6896 - val_accuracy: 0.4900 - val_loss: 0.6946\n",
      "Epoch 56/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6896 - val_accuracy: 0.4900 - val_loss: 0.6946\n",
      "Epoch 57/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5353 - loss: 0.6896 - val_accuracy: 0.4960 - val_loss: 0.6943\n",
      "Epoch 58/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5322 - loss: 0.6895 - val_accuracy: 0.4920 - val_loss: 0.6944\n",
      "Epoch 59/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5368 - loss: 0.6895 - val_accuracy: 0.4920 - val_loss: 0.6944\n",
      "Epoch 60/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5334 - loss: 0.6894 - val_accuracy: 0.4920 - val_loss: 0.6944\n",
      "Epoch 61/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5370 - loss: 0.6894 - val_accuracy: 0.4920 - val_loss: 0.6944\n",
      "Epoch 62/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 0.6894 - val_accuracy: 0.4940 - val_loss: 0.6944\n",
      "Epoch 63/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5433 - loss: 0.6893 - val_accuracy: 0.4920 - val_loss: 0.6943\n",
      "Epoch 64/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5439 - loss: 0.6893 - val_accuracy: 0.4920 - val_loss: 0.6942\n",
      "Epoch 65/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 0.6893 - val_accuracy: 0.4940 - val_loss: 0.6943\n",
      "Epoch 66/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5429 - loss: 0.6892 - val_accuracy: 0.4940 - val_loss: 0.6943\n",
      "Epoch 67/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 0.6892 - val_accuracy: 0.4940 - val_loss: 0.6940\n",
      "Epoch 68/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5437 - loss: 0.6891 - val_accuracy: 0.4960 - val_loss: 0.6940\n",
      "Epoch 69/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5440 - loss: 0.6891 - val_accuracy: 0.4880 - val_loss: 0.6940\n",
      "Epoch 70/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5433 - loss: 0.6891 - val_accuracy: 0.4960 - val_loss: 0.6939\n",
      "Epoch 71/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.6891 - val_accuracy: 0.4960 - val_loss: 0.6940\n",
      "Epoch 72/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5404 - loss: 0.6890 - val_accuracy: 0.4940 - val_loss: 0.6939\n",
      "Epoch 73/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.6890 - val_accuracy: 0.4940 - val_loss: 0.6939\n",
      "Epoch 74/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 0.6889 - val_accuracy: 0.4940 - val_loss: 0.6937\n",
      "Epoch 75/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5421 - loss: 0.6889 - val_accuracy: 0.4940 - val_loss: 0.6937\n",
      "Epoch 76/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6888 - val_accuracy: 0.4960 - val_loss: 0.6938\n",
      "Epoch 77/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5403 - loss: 0.6888 - val_accuracy: 0.4980 - val_loss: 0.6936\n",
      "Epoch 78/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5397 - loss: 0.6888 - val_accuracy: 0.4980 - val_loss: 0.6936\n",
      "Epoch 79/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 0.6887 - val_accuracy: 0.5040 - val_loss: 0.6936\n",
      "Epoch 80/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5388 - loss: 0.6887 - val_accuracy: 0.5040 - val_loss: 0.6937\n",
      "Epoch 81/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5422 - loss: 0.6886 - val_accuracy: 0.4940 - val_loss: 0.6935\n",
      "Epoch 82/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5413 - loss: 0.6886 - val_accuracy: 0.4960 - val_loss: 0.6932\n",
      "Epoch 83/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 0.6885 - val_accuracy: 0.5020 - val_loss: 0.6932\n",
      "Epoch 84/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5393 - loss: 0.6885 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 85/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5454 - loss: 0.6884 - val_accuracy: 0.4980 - val_loss: 0.6937\n",
      "Epoch 86/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5446 - loss: 0.6884 - val_accuracy: 0.4960 - val_loss: 0.6934\n",
      "Epoch 87/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5420 - loss: 0.6883 - val_accuracy: 0.5020 - val_loss: 0.6930\n",
      "Epoch 88/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.6883 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 89/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5436 - loss: 0.6883 - val_accuracy: 0.4960 - val_loss: 0.6930\n",
      "Epoch 90/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5411 - loss: 0.6882 - val_accuracy: 0.4980 - val_loss: 0.6930\n",
      "Epoch 91/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5370 - loss: 0.6882 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
      "Epoch 92/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5361 - loss: 0.6881 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
      "Epoch 93/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5394 - loss: 0.6881 - val_accuracy: 0.5020 - val_loss: 0.6930\n",
      "Epoch 94/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5401 - loss: 0.6880 - val_accuracy: 0.4980 - val_loss: 0.6929\n",
      "Epoch 95/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6880 - val_accuracy: 0.4980 - val_loss: 0.6928\n",
      "Epoch 96/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6879 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
      "Epoch 97/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.6879 - val_accuracy: 0.4940 - val_loss: 0.6928\n",
      "Epoch 98/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5405 - loss: 0.6878 - val_accuracy: 0.4960 - val_loss: 0.6926\n",
      "Epoch 99/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5381 - loss: 0.6878 - val_accuracy: 0.4980 - val_loss: 0.6926\n",
      "Epoch 100/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 0.6877 - val_accuracy: 0.4960 - val_loss: 0.6922\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "JNJ - Accuracy: 0.4960, Precision: 0.4873, Recall: 0.7967, F1 Score: 0.6047\n",
      "Processing JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  4.577072\n",
      "2023-12-26  4.590490\n",
      "2023-12-27  4.627862\n",
      "2023-12-28  4.674954\n",
      "2023-12-29  4.642896\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  167.293760  147.903150\n",
      "2023-12-26  168.049965  148.640593\n",
      "2023-12-27  168.808518  149.440542\n",
      "2023-12-28  169.586812  150.232541\n",
      "2023-12-29  170.278038  150.919008\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  71.112214\n",
      "2023-12-26  71.960606\n",
      "2023-12-27  72.803546\n",
      "2023-12-28  73.536911\n",
      "2023-12-29  73.083903\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  26.875170\n",
      "2023-12-26  27.728324\n",
      "2023-12-27  28.589883\n",
      "2023-12-28  29.483525\n",
      "2023-12-29  30.348901\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    154.453934    147.561201\n",
      "2023-12-26    155.173244    147.961345\n",
      "2023-12-27    155.946927    148.398352\n",
      "2023-12-28    156.662960    148.867333\n",
      "2023-12-29    157.329860    149.322633\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4879 - loss: 0.6933 - val_accuracy: 0.5181 - val_loss: 0.6928\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5252 - loss: 0.6926 - val_accuracy: 0.5181 - val_loss: 0.6928\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5252 - loss: 0.6923 - val_accuracy: 0.5181 - val_loss: 0.6929\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5252 - loss: 0.6921 - val_accuracy: 0.5181 - val_loss: 0.6930\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5252 - loss: 0.6920 - val_accuracy: 0.5201 - val_loss: 0.6931\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5251 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5247 - loss: 0.6919 - val_accuracy: 0.4980 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5247 - loss: 0.6919 - val_accuracy: 0.4920 - val_loss: 0.6933\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 0.6918 - val_accuracy: 0.4799 - val_loss: 0.6933\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5244 - loss: 0.6918 - val_accuracy: 0.4739 - val_loss: 0.6934\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5246 - loss: 0.6918 - val_accuracy: 0.4739 - val_loss: 0.6935\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "JPM - Accuracy: 0.5181, Precision: 0.5181, Recall: 1.0000, F1 Score: 0.6825\n",
      "Processing MCD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  4.794528\n",
      "2023-12-26  4.727765\n",
      "2023-12-27  4.754766\n",
      "2023-12-28  4.823400\n",
      "2023-12-29  4.875009\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  292.329199  275.310938\n",
      "2023-12-26  292.631305  276.263373\n",
      "2023-12-27  293.056554  277.235069\n",
      "2023-12-28  293.109154  278.874787\n",
      "2023-12-29  293.555466  279.877768\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.263781\n",
      "2023-12-26  63.019560\n",
      "2023-12-27  64.103092\n",
      "2023-12-28  64.914854\n",
      "2023-12-29  65.336028\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  19.558127\n",
      "2023-12-26  19.605462\n",
      "2023-12-27  19.738978\n",
      "2023-12-28  19.966301\n",
      "2023-12-29  20.206065\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    279.388281    266.132828\n",
      "2023-12-26    280.266384    266.643077\n",
      "2023-12-27    281.153984    267.274285\n",
      "2023-12-28    282.009103    267.980090\n",
      "2023-12-29    282.922295    268.675323\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5363 - loss: 0.6920 - val_accuracy: 0.5080 - val_loss: 0.6969\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6912 - val_accuracy: 0.5080 - val_loss: 0.6973\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6910 - val_accuracy: 0.5080 - val_loss: 0.6971\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6909 - val_accuracy: 0.5080 - val_loss: 0.6968\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6908 - val_accuracy: 0.5080 - val_loss: 0.6966\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6907 - val_accuracy: 0.5080 - val_loss: 0.6964\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6907 - val_accuracy: 0.5080 - val_loss: 0.6962\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6907 - val_accuracy: 0.5080 - val_loss: 0.6961\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6906 - val_accuracy: 0.5080 - val_loss: 0.6961\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6906 - val_accuracy: 0.5080 - val_loss: 0.6960\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6906 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6906 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6905 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6905 - val_accuracy: 0.5080 - val_loss: 0.6958\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6905 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 0.6904 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6904 - val_accuracy: 0.5080 - val_loss: 0.6959\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6904 - val_accuracy: 0.5080 - val_loss: 0.6960\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6903 - val_accuracy: 0.5080 - val_loss: 0.6960\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6903 - val_accuracy: 0.5080 - val_loss: 0.6960\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6902 - val_accuracy: 0.5080 - val_loss: 0.6960\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6902 - val_accuracy: 0.5080 - val_loss: 0.6961\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6901 - val_accuracy: 0.5080 - val_loss: 0.6962\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6901 - val_accuracy: 0.5080 - val_loss: 0.6962\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "MCD - Accuracy: 0.5080, Precision: 0.5080, Recall: 1.0000, F1 Score: 0.6738\n",
      "Processing MRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.162204\n",
      "2023-12-26  1.246474\n",
      "2023-12-27  1.325871\n",
      "2023-12-28  1.435218\n",
      "2023-12-29  1.524232\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  107.214185   98.476909\n",
      "2023-12-26  107.517581   98.857967\n",
      "2023-12-27  107.553967   99.663194\n",
      "2023-12-28  107.749198  100.294446\n",
      "2023-12-29  108.067146  100.695282\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.598253\n",
      "2023-12-26  57.439172\n",
      "2023-12-27  58.038689\n",
      "2023-12-28  59.374874\n",
      "2023-12-29  59.793991\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22   9.799121\n",
      "2023-12-26  10.042278\n",
      "2023-12-27  10.241374\n",
      "2023-12-28  10.554195\n",
      "2023-12-29  10.878080\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    101.892650    101.573441\n",
      "2023-12-26    102.122109    101.662673\n",
      "2023-12-27    102.327788    101.764205\n",
      "2023-12-28    102.569285    101.891491\n",
      "2023-12-29    102.845819    102.016355\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5146 - loss: 0.6932 - val_accuracy: 0.4719 - val_loss: 0.6938\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6931 - val_accuracy: 0.4578 - val_loss: 0.6940\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.6930 - val_accuracy: 0.4598 - val_loss: 0.6941\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6929 - val_accuracy: 0.4598 - val_loss: 0.6942\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.6929 - val_accuracy: 0.4598 - val_loss: 0.6943\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6928 - val_accuracy: 0.4598 - val_loss: 0.6944\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.6928 - val_accuracy: 0.4598 - val_loss: 0.6944\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.6927 - val_accuracy: 0.4598 - val_loss: 0.6946\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5150 - loss: 0.6926 - val_accuracy: 0.4598 - val_loss: 0.6947\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6926 - val_accuracy: 0.4598 - val_loss: 0.6949\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.6925 - val_accuracy: 0.4598 - val_loss: 0.6951\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "MRK - Accuracy: 0.4719, Precision: 0.5625, Recall: 0.1004, F1 Score: 0.1703\n",
      "Processing MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.831574\n",
      "2023-12-26  2.792836\n",
      "2023-12-27  2.683764\n",
      "2023-12-28  2.663895\n",
      "2023-12-29  2.678377\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  379.890269  364.446209\n",
      "2023-12-26  379.360852  364.582068\n",
      "2023-12-27  377.586850  365.496212\n",
      "2023-12-28  376.887719  365.839643\n",
      "2023-12-29  376.222291  366.219116\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.948831\n",
      "2023-12-26  57.982270\n",
      "2023-12-27  57.632764\n",
      "2023-12-28  58.167712\n",
      "2023-12-29  58.508125\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  21.974784\n",
      "2023-12-26  22.020208\n",
      "2023-12-27  22.026955\n",
      "2023-12-28  22.081749\n",
      "2023-12-29  22.158986\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    371.855002    352.323810\n",
      "2023-12-26    372.045598    353.312688\n",
      "2023-12-27    372.315701    354.191505\n",
      "2023-12-28    372.507002    355.229788\n",
      "2023-12-29    372.718561    356.188384\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4866 - loss: 0.6925 - val_accuracy: 0.5100 - val_loss: 0.6962\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.5100 - val_loss: 0.6960\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.5100 - val_loss: 0.6957\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.5100 - val_loss: 0.6955\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.5100 - val_loss: 0.6953\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.5100 - val_loss: 0.6951\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6921 - val_accuracy: 0.5100 - val_loss: 0.6950\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5187 - loss: 0.6920 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6918 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6917 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5197 - loss: 0.6915 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5191 - loss: 0.6913 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5209 - loss: 0.6911 - val_accuracy: 0.5100 - val_loss: 0.6949\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5238 - loss: 0.6910 - val_accuracy: 0.5100 - val_loss: 0.6950\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5201 - loss: 0.6908 - val_accuracy: 0.5100 - val_loss: 0.6951\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5219 - loss: 0.6906 - val_accuracy: 0.5080 - val_loss: 0.6952\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6905 - val_accuracy: 0.5040 - val_loss: 0.6953\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6903 - val_accuracy: 0.4960 - val_loss: 0.6954\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5236 - loss: 0.6902 - val_accuracy: 0.4940 - val_loss: 0.6955\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6901 - val_accuracy: 0.4900 - val_loss: 0.6956\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "MSFT - Accuracy: 0.5100, Precision: 0.5100, Recall: 1.0000, F1 Score: 0.6755\n",
      "Processing NKE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.966104\n",
      "2023-12-26  1.977977\n",
      "2023-12-27  1.110793\n",
      "2023-12-28  0.552530\n",
      "2023-12-29  0.089053\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  125.468352  105.254719\n",
      "2023-12-26  125.419692  105.345289\n",
      "2023-12-27  125.563684  105.076720\n",
      "2023-12-28  125.657068  104.866247\n",
      "2023-12-29  125.762512  104.628792\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  48.146751\n",
      "2023-12-26  48.126516\n",
      "2023-12-27  47.213444\n",
      "2023-12-28  49.110044\n",
      "2023-12-29  48.841502\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  21.352998\n",
      "2023-12-26  20.741573\n",
      "2023-12-27  20.196659\n",
      "2023-12-28  19.605099\n",
      "2023-12-29  18.988368\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    112.054397    106.165203\n",
      "2023-12-26    112.129370    106.375639\n",
      "2023-12-27    112.237877    106.588830\n",
      "2023-12-28    112.351189    106.821239\n",
      "2023-12-29    112.387973    107.036323\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5290 - loss: 0.6930 - val_accuracy: 0.4839 - val_loss: 0.6953\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6925 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6921 - val_accuracy: 0.4839 - val_loss: 0.6946\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6944\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6942\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6941\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6940\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5288 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6941\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5292 - loss: 0.6913 - val_accuracy: 0.4880 - val_loss: 0.6939\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6912 - val_accuracy: 0.4880 - val_loss: 0.6940\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5308 - loss: 0.6911 - val_accuracy: 0.4900 - val_loss: 0.6940\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5304 - loss: 0.6910 - val_accuracy: 0.4900 - val_loss: 0.6940\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 0.6909 - val_accuracy: 0.4859 - val_loss: 0.6941\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 0.6908 - val_accuracy: 0.4859 - val_loss: 0.6941\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 0.6907 - val_accuracy: 0.4880 - val_loss: 0.6940\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5324 - loss: 0.6906 - val_accuracy: 0.4880 - val_loss: 0.6941\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6905 - val_accuracy: 0.4900 - val_loss: 0.6941\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5323 - loss: 0.6904 - val_accuracy: 0.4880 - val_loss: 0.6943\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5349 - loss: 0.6903 - val_accuracy: 0.4880 - val_loss: 0.6944\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "NKE - Accuracy: 0.4880, Precision: 0.4859, Recall: 1.0000, F1 Score: 0.6540\n",
      "Processing PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -1.395525\n",
      "2023-12-26 -1.291613\n",
      "2023-12-27 -1.186085\n",
      "2023-12-28 -1.115727\n",
      "2023-12-29 -0.984473\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  151.104488  138.688053\n",
      "2023-12-26  150.662980  138.609394\n",
      "2023-12-27  149.953354  138.707579\n",
      "2023-12-28  149.402471  138.728482\n",
      "2023-12-29  148.115903  139.330000\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  45.362424\n",
      "2023-12-26  46.403911\n",
      "2023-12-27  46.595397\n",
      "2023-12-28  46.126599\n",
      "2023-12-29  47.468581\n",
      "After ADX:                dx_30\n",
      "Date                \n",
      "2023-12-22  9.989554\n",
      "2023-12-26  9.914700\n",
      "2023-12-27  9.825308\n",
      "2023-12-28  9.773187\n",
      "2023-12-29  9.603948\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    146.114411    145.248704\n",
      "2023-12-26    145.935460    145.264977\n",
      "2023-12-27    145.726084    145.294104\n",
      "2023-12-28    145.517036    145.312956\n",
      "2023-12-29    145.357388    145.337255\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5053 - loss: 0.6931 - val_accuracy: 0.5120 - val_loss: 0.6980\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6932 - val_accuracy: 0.5120 - val_loss: 0.6992\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6931 - val_accuracy: 0.5120 - val_loss: 0.6995\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6930 - val_accuracy: 0.5120 - val_loss: 0.6998\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5116 - loss: 0.6930 - val_accuracy: 0.5120 - val_loss: 0.6999\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5116 - loss: 0.6930 - val_accuracy: 0.5120 - val_loss: 0.7000\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.7001\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.7001\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.7002\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.7002\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.7002\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "PG - Accuracy: 0.5120, Precision: 0.5120, Recall: 1.0000, F1 Score: 0.6773\n",
      "Processing CRM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  11.093812\n",
      "2023-12-26  10.870213\n",
      "2023-12-27  10.610925\n",
      "2023-12-28  10.196176\n",
      "2023-12-29   9.560948\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  276.087092  227.358585\n",
      "2023-12-26  275.287562  232.289279\n",
      "2023-12-27  273.201073  238.543829\n",
      "2023-12-28  270.546866  244.710971\n",
      "2023-12-29  270.910589  245.468039\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  70.397004\n",
      "2023-12-26  70.294637\n",
      "2023-12-27  70.479672\n",
      "2023-12-28  69.459232\n",
      "2023-12-29  67.301722\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  28.843087\n",
      "2023-12-26  29.445653\n",
      "2023-12-27  30.039490\n",
      "2023-12-28  30.606751\n",
      "2023-12-29  30.976245\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    241.266462    222.681870\n",
      "2023-12-26    243.014453    223.736183\n",
      "2023-12-27    244.724222    224.783349\n",
      "2023-12-28    246.199994    225.876052\n",
      "2023-12-29    247.653165    226.894302\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 0.6930 - val_accuracy: 0.5020 - val_loss: 0.6951\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.6926 - val_accuracy: 0.5020 - val_loss: 0.6955\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.6926 - val_accuracy: 0.5020 - val_loss: 0.6954\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6925 - val_accuracy: 0.5020 - val_loss: 0.6954\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6924 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6924 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6923 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6922 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.6922 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6921 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 0.6920 - val_accuracy: 0.5020 - val_loss: 0.6953\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "CRM - Accuracy: 0.5020, Precision: 0.5020, Recall: 1.0000, F1 Score: 0.6684\n",
      "Processing TRV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.451946\n",
      "2023-12-26  3.476579\n",
      "2023-12-27  3.577158\n",
      "2023-12-28  3.671298\n",
      "2023-12-29  3.794879\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  185.985504  174.811400\n",
      "2023-12-26  186.456501  175.277009\n",
      "2023-12-27  186.783211  176.212831\n",
      "2023-12-28  187.100647  177.169148\n",
      "2023-12-29  188.018337  177.326840\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  63.951916\n",
      "2023-12-26  65.071496\n",
      "2023-12-27  66.353621\n",
      "2023-12-28  66.936263\n",
      "2023-12-29  67.876425\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  16.493753\n",
      "2023-12-26  16.890550\n",
      "2023-12-27  17.362056\n",
      "2023-12-28  17.896022\n",
      "2023-12-29  18.467588\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    176.862166    169.584116\n",
      "2023-12-26    177.458419    169.991430\n",
      "2023-12-27    178.071039    170.441079\n",
      "2023-12-28    178.782630    170.924616\n",
      "2023-12-29    179.504940    171.401361\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5393 - loss: 0.6917 - val_accuracy: 0.5181 - val_loss: 0.6978\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6898 - val_accuracy: 0.5181 - val_loss: 0.6984\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6893 - val_accuracy: 0.5181 - val_loss: 0.6981\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6889 - val_accuracy: 0.5181 - val_loss: 0.6977\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6886 - val_accuracy: 0.5181 - val_loss: 0.6975\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6883 - val_accuracy: 0.5181 - val_loss: 0.6973\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6880 - val_accuracy: 0.5181 - val_loss: 0.6971\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6877 - val_accuracy: 0.5181 - val_loss: 0.6969\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6874 - val_accuracy: 0.5181 - val_loss: 0.6968\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6872 - val_accuracy: 0.5181 - val_loss: 0.6968\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6869 - val_accuracy: 0.5181 - val_loss: 0.6968\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6867 - val_accuracy: 0.5181 - val_loss: 0.6969\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6865 - val_accuracy: 0.5181 - val_loss: 0.6970\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6863 - val_accuracy: 0.5181 - val_loss: 0.6970\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6861 - val_accuracy: 0.5181 - val_loss: 0.6971\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6859 - val_accuracy: 0.5181 - val_loss: 0.6971\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6857 - val_accuracy: 0.5181 - val_loss: 0.6972\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6856 - val_accuracy: 0.5181 - val_loss: 0.6973\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6854 - val_accuracy: 0.5181 - val_loss: 0.6974\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.6853 - val_accuracy: 0.5181 - val_loss: 0.6975\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6852 - val_accuracy: 0.5181 - val_loss: 0.6976\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "TRV - Accuracy: 0.5181, Precision: 0.5181, Recall: 1.0000, F1 Score: 0.6825\n",
      "Processing UNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -3.984858\n",
      "2023-12-26 -4.484649\n",
      "2023-12-27 -4.606741\n",
      "2023-12-28 -4.482945\n",
      "2023-12-29 -4.210650\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  556.882605  511.201431\n",
      "2023-12-26  557.078337  508.852178\n",
      "2023-12-27  557.080895  507.272325\n",
      "2023-12-28  557.143434  506.390395\n",
      "2023-12-29  555.290848  505.801007\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  46.408365\n",
      "2023-12-26  46.297413\n",
      "2023-12-27  47.575760\n",
      "2023-12-28  48.544492\n",
      "2023-12-29  49.266049\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  15.057547\n",
      "2023-12-26  15.119187\n",
      "2023-12-27  15.111571\n",
      "2023-12-28  14.921791\n",
      "2023-12-29  14.724275\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    534.098843    527.848743\n",
      "2023-12-26    533.459423    528.138934\n",
      "2023-12-27    532.866440    528.303739\n",
      "2023-12-28    532.412743    528.587449\n",
      "2023-12-29    532.078498    528.878165\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5301 - loss: 0.6926 - val_accuracy: 0.5321 - val_loss: 0.6918\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6922 - val_accuracy: 0.5321 - val_loss: 0.6916\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6920 - val_accuracy: 0.5321 - val_loss: 0.6915\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6918 - val_accuracy: 0.5321 - val_loss: 0.6913\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6917 - val_accuracy: 0.5321 - val_loss: 0.6911\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6916 - val_accuracy: 0.5321 - val_loss: 0.6910\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5321 - val_loss: 0.6909\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6913 - val_accuracy: 0.5321 - val_loss: 0.6907\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6912 - val_accuracy: 0.5321 - val_loss: 0.6904\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6911 - val_accuracy: 0.5321 - val_loss: 0.6902\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6909 - val_accuracy: 0.5321 - val_loss: 0.6901\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6908 - val_accuracy: 0.5321 - val_loss: 0.6899\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6906 - val_accuracy: 0.5321 - val_loss: 0.6898\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 0.6905 - val_accuracy: 0.5321 - val_loss: 0.6897\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6904 - val_accuracy: 0.5321 - val_loss: 0.6895\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5304 - loss: 0.6903 - val_accuracy: 0.5321 - val_loss: 0.6895\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5304 - loss: 0.6901 - val_accuracy: 0.5321 - val_loss: 0.6894\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6900 - val_accuracy: 0.5321 - val_loss: 0.6893\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5325 - loss: 0.6899 - val_accuracy: 0.5321 - val_loss: 0.6892\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.6898 - val_accuracy: 0.5321 - val_loss: 0.6892\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5347 - loss: 0.6897 - val_accuracy: 0.5321 - val_loss: 0.6891\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5342 - loss: 0.6896 - val_accuracy: 0.5321 - val_loss: 0.6891\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 0.6895 - val_accuracy: 0.5321 - val_loss: 0.6890\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6894 - val_accuracy: 0.5321 - val_loss: 0.6890\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5351 - loss: 0.6893 - val_accuracy: 0.5321 - val_loss: 0.6889\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5388 - loss: 0.6893 - val_accuracy: 0.5321 - val_loss: 0.6889\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5430 - loss: 0.6892 - val_accuracy: 0.5321 - val_loss: 0.6888\n",
      "Epoch 28/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 0.6891 - val_accuracy: 0.5321 - val_loss: 0.6889\n",
      "Epoch 29/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5505 - loss: 0.6890 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 30/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5433 - loss: 0.6889 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 31/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 0.6888 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 32/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5454 - loss: 0.6888 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 33/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.6887 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 34/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5557 - loss: 0.6886 - val_accuracy: 0.5341 - val_loss: 0.6888\n",
      "Epoch 35/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5562 - loss: 0.6886 - val_accuracy: 0.5321 - val_loss: 0.6888\n",
      "Epoch 36/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5544 - loss: 0.6885 - val_accuracy: 0.5361 - val_loss: 0.6888\n",
      "Epoch 37/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5554 - loss: 0.6884 - val_accuracy: 0.5361 - val_loss: 0.6888\n",
      "Epoch 38/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5539 - loss: 0.6884 - val_accuracy: 0.5402 - val_loss: 0.6888\n",
      "Epoch 39/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5546 - loss: 0.6883 - val_accuracy: 0.5422 - val_loss: 0.6888\n",
      "Epoch 40/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5524 - loss: 0.6883 - val_accuracy: 0.5422 - val_loss: 0.6888\n",
      "Epoch 41/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 0.6882 - val_accuracy: 0.5422 - val_loss: 0.6888\n",
      "Epoch 42/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5542 - loss: 0.6881 - val_accuracy: 0.5422 - val_loss: 0.6889\n",
      "Epoch 43/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5602 - loss: 0.6881 - val_accuracy: 0.5422 - val_loss: 0.6889\n",
      "Epoch 44/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5594 - loss: 0.6880 - val_accuracy: 0.5422 - val_loss: 0.6888\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "UNH - Accuracy: 0.5341, Precision: 0.5332, Recall: 1.0000, F1 Score: 0.6955\n",
      "Processing VZ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.335397\n",
      "2023-12-26  0.305032\n",
      "2023-12-27  0.264853\n",
      "2023-12-28  0.244028\n",
      "2023-12-29  0.240881\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  36.917819  35.066623\n",
      "2023-12-26  36.914054  35.082766\n",
      "2023-12-27  36.919430  35.062156\n",
      "2023-12-28  36.915352  35.040526\n",
      "2023-12-29  36.854980  35.040911\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.780100\n",
      "2023-12-26  57.720500\n",
      "2023-12-27  56.692927\n",
      "2023-12-28  57.521290\n",
      "2023-12-29  58.479749\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.217499\n",
      "2023-12-26  21.933355\n",
      "2023-12-27  21.603934\n",
      "2023-12-28  21.385516\n",
      "2023-12-29  21.189671\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     35.565494     33.454810\n",
      "2023-12-26     35.621671     33.546017\n",
      "2023-12-27     35.668962     33.644625\n",
      "2023-12-28     35.720061     33.742672\n",
      "2023-12-29     35.774017     33.850887\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4989 - loss: 0.6933 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: 0.6931 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 0.6930 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 0.6930 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5122 - loss: 0.6929 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5132 - loss: 0.6928 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5141 - loss: 0.6927 - val_accuracy: 0.5020 - val_loss: 0.6930\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5136 - loss: 0.6927 - val_accuracy: 0.5060 - val_loss: 0.6931\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.6926 - val_accuracy: 0.5060 - val_loss: 0.6931\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 0.6926 - val_accuracy: 0.5060 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 0.6925 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.6924 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5123 - loss: 0.6923 - val_accuracy: 0.5020 - val_loss: 0.6931\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.6922 - val_accuracy: 0.5060 - val_loss: 0.6931\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5135 - loss: 0.6922 - val_accuracy: 0.5141 - val_loss: 0.6932\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6921 - val_accuracy: 0.5221 - val_loss: 0.6932\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5127 - loss: 0.6919 - val_accuracy: 0.5221 - val_loss: 0.6932\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "VZ - Accuracy: 0.5020, Precision: 0.5020, Recall: 1.0000, F1 Score: 0.6684\n",
      "Processing V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.065393\n",
      "2023-12-26  2.939801\n",
      "2023-12-27  2.789657\n",
      "2023-12-28  2.756830\n",
      "2023-12-29  2.695728\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  260.188636  250.683264\n",
      "2023-12-26  260.359126  251.011913\n",
      "2023-12-27  260.296948  251.669677\n",
      "2023-12-28  260.520951  252.059159\n",
      "2023-12-29  260.815841  252.129180\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  59.956970\n",
      "2023-12-26  60.558161\n",
      "2023-12-27  60.263263\n",
      "2023-12-28  61.502714\n",
      "2023-12-29  61.435291\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  17.120703\n",
      "2023-12-26  17.359886\n",
      "2023-12-27  17.566841\n",
      "2023-12-28  17.848365\n",
      "2023-12-29  18.153372\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    252.927660    243.690333\n",
      "2023-12-26    253.388685    244.181496\n",
      "2023-12-27    253.861309    244.648010\n",
      "2023-12-28    254.307419    245.179565\n",
      "2023-12-29    254.713095    245.670439\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5161 - loss: 0.6914 - val_accuracy: 0.5181 - val_loss: 0.6941\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5181 - val_loss: 0.6938\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6937\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6935\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6934\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6931\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6930\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6929\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6928\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6909 - val_accuracy: 0.5181 - val_loss: 0.6927\n",
      "Epoch 12/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5327 - loss: 0.6908 - val_accuracy: 0.5181 - val_loss: 0.6927\n",
      "Epoch 13/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6907 - val_accuracy: 0.5181 - val_loss: 0.6926\n",
      "Epoch 14/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6906 - val_accuracy: 0.5181 - val_loss: 0.6926\n",
      "Epoch 15/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6905 - val_accuracy: 0.5181 - val_loss: 0.6926\n",
      "Epoch 16/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6904 - val_accuracy: 0.5181 - val_loss: 0.6926\n",
      "Epoch 17/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6903 - val_accuracy: 0.5181 - val_loss: 0.6925\n",
      "Epoch 18/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 0.6902 - val_accuracy: 0.5221 - val_loss: 0.6926\n",
      "Epoch 19/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 0.6900 - val_accuracy: 0.5261 - val_loss: 0.6926\n",
      "Epoch 20/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.6899 - val_accuracy: 0.5181 - val_loss: 0.6926\n",
      "Epoch 21/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6898 - val_accuracy: 0.5161 - val_loss: 0.6926\n",
      "Epoch 22/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5279 - loss: 0.6896 - val_accuracy: 0.5120 - val_loss: 0.6926\n",
      "Epoch 23/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5272 - loss: 0.6895 - val_accuracy: 0.5100 - val_loss: 0.6926\n",
      "Epoch 24/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5256 - loss: 0.6894 - val_accuracy: 0.5100 - val_loss: 0.6926\n",
      "Epoch 25/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5256 - loss: 0.6893 - val_accuracy: 0.5080 - val_loss: 0.6926\n",
      "Epoch 26/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 0.6893 - val_accuracy: 0.5100 - val_loss: 0.6926\n",
      "Epoch 27/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5295 - loss: 0.6892 - val_accuracy: 0.5141 - val_loss: 0.6927\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "V - Accuracy: 0.5181, Precision: 0.5181, Recall: 1.0000, F1 Score: 0.6825\n",
      "Processing WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -0.319304\n",
      "2023-12-26 -0.243216\n",
      "2023-12-27 -0.142009\n",
      "2023-12-28 -0.069285\n",
      "2023-12-29 -0.009405\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  52.238773  49.776829\n",
      "2023-12-26  52.251080  49.771808\n",
      "2023-12-27  52.236280  49.780882\n",
      "2023-12-28  52.356325  49.729283\n",
      "2023-12-29  52.485821  49.683747\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  49.341277\n",
      "2023-12-26  49.037735\n",
      "2023-12-27  50.949645\n",
      "2023-12-28  50.536043\n",
      "2023-12-29  50.642997\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  13.616418\n",
      "2023-12-26  13.276956\n",
      "2023-12-27  12.843049\n",
      "2023-12-28  12.447747\n",
      "2023-12-29  12.038234\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     51.646541     52.429363\n",
      "2023-12-26     51.545403     52.413206\n",
      "2023-12-27     51.444105     52.404226\n",
      "2023-12-28     51.339716     52.399087\n",
      "2023-12-29     51.212792     52.383890\n",
      "After dropping NaN values: (2487, 15)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\leand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5114 - loss: 0.6930 - val_accuracy: 0.5442 - val_loss: 0.6907\n",
      "Epoch 2/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6928 - val_accuracy: 0.5442 - val_loss: 0.6911\n",
      "Epoch 3/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6928 - val_accuracy: 0.5442 - val_loss: 0.6915\n",
      "Epoch 4/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6928 - val_accuracy: 0.5442 - val_loss: 0.6916\n",
      "Epoch 5/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6929 - val_accuracy: 0.5442 - val_loss: 0.6919\n",
      "Epoch 6/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6929 - val_accuracy: 0.5442 - val_loss: 0.6920\n",
      "Epoch 7/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6930 - val_accuracy: 0.5502 - val_loss: 0.6922\n",
      "Epoch 8/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.6930 - val_accuracy: 0.5341 - val_loss: 0.6923\n",
      "Epoch 9/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.6930 - val_accuracy: 0.5261 - val_loss: 0.6924\n",
      "Epoch 10/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5153 - loss: 0.6931 - val_accuracy: 0.5120 - val_loss: 0.6925\n",
      "Epoch 11/100\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5153 - loss: 0.6931 - val_accuracy: 0.5141 - val_loss: 0.6926\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "WMT - Accuracy: 0.5442, Precision: 0.5442, Recall: 1.0000, F1 Score: 0.7048\n",
      "Finished processing all tickers.\n"
     ]
    }
   ],
   "source": [
    "## Step 4 - Loop through Each Ticker\n",
    "dow30_tickers = get_dow30_tickers()\n",
    "models = {}\n",
    "scalers = {}\n",
    "\n",
    "features = ['Adj Close', 'Volume', 'boll_ub', 'boll_lb', 'rsi_30', 'close_30_sma', 'close_60_sma']\n",
    "\n",
    "for ticker in dow30_tickers:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "    try:\n",
    "        data = load_stock_data(ticker, start_date, end_date)\n",
    "        data = feature_engineering(data)\n",
    "       \n",
    "        X_train, X_test, y_train, y_test, scaler = prepare_data_for_modeling(data, features)\n",
    "\n",
    "        ## Build and Train the LSTM Model\n",
    "        lstm = Sequential()\n",
    "        lstm.add(LSTM(32, input_shape=(1, X_train.shape[2]), activation='relu', return_sequences=False))\n",
    "        lstm.add(Dense(1, activation='sigmoid'))\n",
    "        lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        lstm.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1, shuffle=False, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "        ## Make Predictions\n",
    "        y_pred = (lstm.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'{ticker} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "        models[ticker] = lstm\n",
    "        scalers[ticker] = scaler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "print(\"Finished processing all tickers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5 - Generate Future Predictions\n",
    "def generate_predictions(models, scalers, tickers, historical_data, future_end_date):\n",
    "    predictions = {}\n",
    "    for ticker in tickers:\n",
    "        model = models.get(ticker)\n",
    "        scaler = scalers.get(ticker)\n",
    "        if model and scaler:\n",
    "            try:\n",
    "                # Load historical data up to the end of the current week\n",
    "                historical_data_ticker = historical_data[ticker]\n",
    "                new_data = load_stock_data(ticker, \"2024-01-01\", future_end_date)\n",
    "                \n",
    "                # Append the new data to the historical data\n",
    "                combined_data = pd.concat([historical_data_ticker, new_data])\n",
    "                \n",
    "                # Apply feature engineering to the combined dataset\n",
    "                combined_data = feature_engineering(combined_data)\n",
    "                \n",
    "                # Ensure we have enough data after feature engineering\n",
    "                if len(combined_data) < 60:\n",
    "                    print(f\"Insufficient data for {ticker} after feature engineering. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                future_features = combined_data[features]\n",
    "                \n",
    "                # Transform features using the scaler\n",
    "                future_features_scaled = scaler.transform(future_features)\n",
    "                future_features_scaled = np.array(future_features_scaled).reshape((future_features_scaled.shape[0], 1, future_features_scaled.shape[1]))\n",
    "                \n",
    "                # Predict probabilities\n",
    "                predictions[ticker] = model.predict(future_features_scaled).flatten()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing future data for {ticker}: {e}\")\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Step 6 - Generate Trading Signals\n",
    "def generate_trading_signals(predictions):\n",
    "    signals = {}\n",
    "    for ticker, pred_probs in predictions.items():\n",
    "        # Compute average confidence score\n",
    "        avg_confidence = np.mean(pred_probs)\n",
    "        signals[ticker] = avg_confidence\n",
    "    return signals\n",
    "\n",
    "## Step 7 - Portfolio Allocation\n",
    "def allocate_portfolio(signals, total_investment):\n",
    "    allocations = {}\n",
    "    total_confidence = sum(signals.values())\n",
    "   \n",
    "    if total_confidence > 0:\n",
    "        for ticker, confidence in signals.items():\n",
    "            # Allocate proportionally based on confidence\n",
    "            allocations[ticker] = (confidence / total_confidence) * total_investment\n",
    "    return allocations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.389954\n",
      "2023-12-26  2.450287\n",
      "2023-12-27  2.510682\n",
      "2023-12-28  2.591288\n",
      "2023-12-29  2.600801\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  88.913152  79.275502\n",
      "2023-12-26  89.163122  79.927264\n",
      "2023-12-27  89.539265  80.386694\n",
      "2023-12-28  89.924442  80.917952\n",
      "2023-12-29  90.143257  81.536343\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.468146\n",
      "2023-12-26  64.418466\n",
      "2023-12-27  65.082806\n",
      "2023-12-28  66.071003\n",
      "2023-12-29  65.326090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.019013\n",
      "2023-12-26  18.226646\n",
      "2023-12-27  18.471283\n",
      "2023-12-28  18.798848\n",
      "2023-12-29  19.115495\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     81.731357     77.002458\n",
      "2023-12-26     82.187066     77.219457\n",
      "2023-12-27     82.663144     77.490600\n",
      "2023-12-28     83.103974     77.793840\n",
      "2023-12-29     83.485141     78.102363\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  6.506604\n",
      "2023-12-26  6.583286\n",
      "2023-12-27  6.655277\n",
      "2023-12-28  6.694323\n",
      "2023-12-29  6.612270\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  186.207809  158.873356\n",
      "2023-12-26  187.387964  159.864926\n",
      "2023-12-27  188.623254  160.749842\n",
      "2023-12-28  189.856706  161.534548\n",
      "2023-12-29  190.974155  162.058772\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  68.217054\n",
      "2023-12-26  68.435078\n",
      "2023-12-27  69.054447\n",
      "2023-12-28  69.471335\n",
      "2023-12-29  68.874685\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  23.561045\n",
      "2023-12-26  24.094964\n",
      "2023-12-27  24.652370\n",
      "2023-12-28  25.231737\n",
      "2023-12-29  25.741996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    167.900736    157.526338\n",
      "2023-12-26    168.943666    158.143583\n",
      "2023-12-27    170.024244    158.774223\n",
      "2023-12-28    171.044386    159.489933\n",
      "2023-12-29    171.966114    160.172064\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.190549\n",
      "2023-12-26  3.534258\n",
      "2023-12-27  3.969977\n",
      "2023-12-28  4.417798\n",
      "2023-12-29  4.683726\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  279.187840  259.128633\n",
      "2023-12-26  280.307673  259.942837\n",
      "2023-12-27  281.861911  260.458600\n",
      "2023-12-28  283.616289  260.857970\n",
      "2023-12-29  285.149305  261.135830\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  59.519291\n",
      "2023-12-26  59.329459\n",
      "2023-12-27  60.642995\n",
      "2023-12-28  61.584851\n",
      "2023-12-29  61.239201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  11.614499\n",
      "2023-12-26  11.834366\n",
      "2023-12-27  12.151005\n",
      "2023-12-28  12.525772\n",
      "2023-12-29  12.810566\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    266.838560    266.268769\n",
      "2023-12-26    267.451888    266.551808\n",
      "2023-12-27    268.171791    266.917952\n",
      "2023-12-28    268.846570    267.402138\n",
      "2023-12-29    269.408817    267.806922\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.135958\n",
      "2023-12-26  3.118650\n",
      "2023-12-27  3.063965\n",
      "2023-12-28  2.989395\n",
      "2023-12-29  2.782032\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  154.696716  142.461283\n",
      "2023-12-26  155.314929  142.411071\n",
      "2023-12-27  155.854273  142.502726\n",
      "2023-12-28  156.311164  142.751835\n",
      "2023-12-29  156.488309  143.159691\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  60.603073\n",
      "2023-12-26  60.591470\n",
      "2023-12-27  60.507526\n",
      "2023-12-28  60.539846\n",
      "2023-12-29  58.749686\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  13.690745\n",
      "2023-12-26  13.829861\n",
      "2023-12-27  14.013525\n",
      "2023-12-28  14.175419\n",
      "2023-12-29  14.157813\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    147.274000    139.104500\n",
      "2023-12-26    147.602333    139.542667\n",
      "2023-12-27    147.960666    139.940667\n",
      "2023-12-28    148.213333    140.418333\n",
      "2023-12-29    148.504667    140.834000\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.647959\n",
      "2023-12-26  2.317722\n",
      "2023-12-27  2.040522\n",
      "2023-12-28  1.834263\n",
      "2023-12-29  1.568314\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  198.589529  187.283218\n",
      "2023-12-26  198.478607  187.718909\n",
      "2023-12-27  198.395451  188.076026\n",
      "2023-12-28  198.165457  188.725429\n",
      "2023-12-29  197.955942  189.191968\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.254946\n",
      "2023-12-26  56.555370\n",
      "2023-12-27  56.654974\n",
      "2023-12-28  57.092629\n",
      "2023-12-29  55.672685\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.320859\n",
      "2023-12-26  18.198209\n",
      "2023-12-27  17.919517\n",
      "2023-12-28  17.734529\n",
      "2023-12-29  17.425307\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    191.366830    183.044050\n",
      "2023-12-26    191.587659    183.410415\n",
      "2023-12-27    191.864940    183.736321\n",
      "2023-12-28    192.068834    184.091753\n",
      "2023-12-29    192.218931    184.408858\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  13.771849\n",
      "2023-12-26  13.461206\n",
      "2023-12-27  13.009378\n",
      "2023-12-28  12.367526\n",
      "2023-12-29  11.748438\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  273.481962  215.949037\n",
      "2023-12-26  274.179991  219.600008\n",
      "2023-12-27  274.469109  223.283891\n",
      "2023-12-28  274.100712  227.244289\n",
      "2023-12-29  274.212016  230.035985\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  72.628640\n",
      "2023-12-26  73.404074\n",
      "2023-12-27  72.777817\n",
      "2023-12-28  71.184406\n",
      "2023-12-29  71.299556\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  30.152536\n",
      "2023-12-26  30.814255\n",
      "2023-12-27  31.473025\n",
      "2023-12-28  31.905504\n",
      "2023-12-29  32.326469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    233.407000    210.323667\n",
      "2023-12-26    235.611667    211.508834\n",
      "2023-12-27    237.530334    212.746667\n",
      "2023-12-28    239.293001    213.937167\n",
      "2023-12-29    241.024667    215.169334\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  10.809041\n",
      "2023-12-26  11.290983\n",
      "2023-12-27  11.736098\n",
      "2023-12-28  11.853386\n",
      "2023-12-29  11.714856\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  296.327808  231.593239\n",
      "2023-12-26  299.591099  233.094857\n",
      "2023-12-27  302.650403  235.035544\n",
      "2023-12-28  304.938676  237.432171\n",
      "2023-12-29  306.508654  240.302132\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  65.708420\n",
      "2023-12-26  67.585824\n",
      "2023-12-27  68.430600\n",
      "2023-12-28  67.524015\n",
      "2023-12-29  66.632900\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.549861\n",
      "2023-12-26  19.273801\n",
      "2023-12-27  20.018815\n",
      "2023-12-28  20.740104\n",
      "2023-12-29  21.284392\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    257.456844    253.669566\n",
      "2023-12-26    259.298999    254.065215\n",
      "2023-12-27    261.157616    254.522820\n",
      "2023-12-28    262.771600    255.005051\n",
      "2023-12-29    264.239398    255.531891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.051432\n",
      "2023-12-26  1.283365\n",
      "2023-12-27  1.411392\n",
      "2023-12-28  1.328433\n",
      "2023-12-29  1.200642\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  149.447753  136.831083\n",
      "2023-12-26  150.318657  136.748529\n",
      "2023-12-27  150.982147  136.711803\n",
      "2023-12-28  151.238857  137.028973\n",
      "2023-12-29  151.369041  137.443288\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  51.680810\n",
      "2023-12-26  53.209339\n",
      "2023-12-27  52.576787\n",
      "2023-12-28  49.947765\n",
      "2023-12-29  49.221978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  19.168902\n",
      "2023-12-26  18.560335\n",
      "2023-12-27  17.957627\n",
      "2023-12-28  17.531170\n",
      "2023-12-29  17.175811\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    142.284917    147.527762\n",
      "2023-12-26    142.642137    147.291734\n",
      "2023-12-27    142.949114    147.081143\n",
      "2023-12-28    143.152314    146.829323\n",
      "2023-12-29    143.319124    146.630380\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -0.079737\n",
      "2023-12-26 -0.020302\n",
      "2023-12-27  0.038951\n",
      "2023-12-28  0.088044\n",
      "2023-12-29  0.128619\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  49.477523  46.034496\n",
      "2023-12-26  49.620491  46.120859\n",
      "2023-12-27  49.754252  46.239851\n",
      "2023-12-28  49.878277  46.352964\n",
      "2023-12-29  50.003730  46.436349\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  47.654651\n",
      "2023-12-26  48.451977\n",
      "2023-12-27  49.127018\n",
      "2023-12-28  49.298735\n",
      "2023-12-29  49.475174\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.759063\n",
      "2023-12-26  22.472070\n",
      "2023-12-27  22.138082\n",
      "2023-12-28  21.790178\n",
      "2023-12-29  21.510879\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     48.088296     49.934079\n",
      "2023-12-26     48.013153     49.883748\n",
      "2023-12-27     47.954926     49.825845\n",
      "2023-12-28     47.867422     49.774287\n",
      "2023-12-29     47.777642     49.726631\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.350238\n",
      "2023-12-26  0.329580\n",
      "2023-12-27  0.321419\n",
      "2023-12-28  0.314503\n",
      "2023-12-29  0.319636\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  58.747124  56.622262\n",
      "2023-12-26  58.740163  56.684529\n",
      "2023-12-27  58.743695  56.739350\n",
      "2023-12-28  58.708991  56.870528\n",
      "2023-12-29  58.729875  56.897881\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  53.559845\n",
      "2023-12-26  54.557063\n",
      "2023-12-27  55.179309\n",
      "2023-12-28  55.348006\n",
      "2023-12-29  56.116763\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  11.417479\n",
      "2023-12-26  11.047345\n",
      "2023-12-27  10.689212\n",
      "2023-12-28  10.377879\n",
      "2023-12-29  10.115714\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     57.168742     55.464373\n",
      "2023-12-26     57.243824     55.513958\n",
      "2023-12-27     57.316990     55.574144\n",
      "2023-12-28     57.385935     55.644753\n",
      "2023-12-29     57.457206     55.715710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.711233\n",
      "2023-12-26  0.555955\n",
      "2023-12-27  0.382701\n",
      "2023-12-28  0.244188\n",
      "2023-12-29  0.124148\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  94.064274  89.768311\n",
      "2023-12-26  93.615433  89.827864\n",
      "2023-12-27  93.673203  89.588977\n",
      "2023-12-28  93.703923  89.379133\n",
      "2023-12-29  93.706805  89.167323\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  52.804370\n",
      "2023-12-26  52.683228\n",
      "2023-12-27  51.684420\n",
      "2023-12-28  51.717654\n",
      "2023-12-29  51.516083\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  17.776530\n",
      "2023-12-26  17.577500\n",
      "2023-12-27  17.297793\n",
      "2023-12-28  17.016418\n",
      "2023-12-29  16.726693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     92.100409     87.251392\n",
      "2023-12-26     92.198846     87.420002\n",
      "2023-12-27     92.239676     87.568904\n",
      "2023-12-28     92.227261     87.753359\n",
      "2023-12-29     92.116609     87.939628\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (1205, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.233266\n",
      "2023-12-26  1.302879\n",
      "2023-12-27  1.342572\n",
      "2023-12-28  1.321017\n",
      "2023-12-29  1.258726\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  54.411207  47.984420\n",
      "2023-12-26  54.807861  48.103061\n",
      "2023-12-27  55.165621  48.205744\n",
      "2023-12-28  55.398142  48.353673\n",
      "2023-12-29  55.555490  48.497759\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.984922\n",
      "2023-12-26  64.447043\n",
      "2023-12-27  64.447043\n",
      "2023-12-28  62.304359\n",
      "2023-12-29  60.610600\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  12.951968\n",
      "2023-12-26  13.466117\n",
      "2023-12-27  13.963128\n",
      "2023-12-28  14.335276\n",
      "2023-12-29  14.532532\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     50.520550     49.106964\n",
      "2023-12-26     50.744921     49.185790\n",
      "2023-12-27     50.976989     49.268785\n",
      "2023-12-28     51.135391     49.348467\n",
      "2023-12-29     51.265715     49.420365\n",
      "After dropping NaN values: (1176, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  13.885094\n",
      "2023-12-26  13.771040\n",
      "2023-12-27  13.750715\n",
      "2023-12-28  13.730045\n",
      "2023-12-29  13.506993\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  387.832499  318.588055\n",
      "2023-12-26  389.937889  321.087023\n",
      "2023-12-27  391.890607  324.027805\n",
      "2023-12-28  394.036332  326.437041\n",
      "2023-12-29  395.592248  329.246582\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  67.636859\n",
      "2023-12-26  67.906394\n",
      "2023-12-27  68.712282\n",
      "2023-12-28  69.249449\n",
      "2023-12-29  68.843987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.338823\n",
      "2023-12-26  23.033414\n",
      "2023-12-27  23.769566\n",
      "2023-12-28  24.521653\n",
      "2023-12-29  25.245340\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    345.012025    324.121336\n",
      "2023-12-26    346.944917    325.119435\n",
      "2023-12-27    348.926547    326.247467\n",
      "2023-12-28    350.586294    327.609238\n",
      "2023-12-29    352.261532    328.920016\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  12.444255\n",
      "2023-12-26  12.060427\n",
      "2023-12-27  11.560841\n",
      "2023-12-28  10.945541\n",
      "2023-12-29  10.274945\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  358.784178  298.027807\n",
      "2023-12-26  359.562672  301.243871\n",
      "2023-12-27  359.937631  304.549164\n",
      "2023-12-28  359.527947  308.546302\n",
      "2023-12-29  358.723402  312.614504\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  68.807103\n",
      "2023-12-26  69.072377\n",
      "2023-12-27  68.420283\n",
      "2023-12-28  67.432436\n",
      "2023-12-29  66.742323\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  26.809036\n",
      "2023-12-26  27.334479\n",
      "2023-12-27  27.779480\n",
      "2023-12-28  28.120907\n",
      "2023-12-29  28.276407\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    318.260429    301.725882\n",
      "2023-12-26    320.223787    302.534811\n",
      "2023-12-27    322.276536    303.368987\n",
      "2023-12-28    323.782176    304.312862\n",
      "2023-12-29    325.112108    305.236054\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.978789\n",
      "2023-12-26  4.128490\n",
      "2023-12-27  4.276070\n",
      "2023-12-28  4.354802\n",
      "2023-12-29  4.409475\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  205.744468  189.556315\n",
      "2023-12-26  206.612606  190.179046\n",
      "2023-12-27  207.596115  190.654749\n",
      "2023-12-28  208.355054  191.370849\n",
      "2023-12-29  209.177382  191.912761\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  64.398526\n",
      "2023-12-26  66.332043\n",
      "2023-12-27  67.087120\n",
      "2023-12-28  67.203567\n",
      "2023-12-29  67.630134\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  16.200170\n",
      "2023-12-26  16.658072\n",
      "2023-12-27  17.171945\n",
      "2023-12-28  17.688467\n",
      "2023-12-29  18.200781\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    194.544005    187.461051\n",
      "2023-12-26    195.247394    187.863047\n",
      "2023-12-27    195.989696    188.316115\n",
      "2023-12-28    196.613941    188.795753\n",
      "2023-12-29    197.278748    189.262001\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.704118\n",
      "2023-12-26  2.651478\n",
      "2023-12-27  2.599419\n",
      "2023-12-28  2.551511\n",
      "2023-12-29  2.469380\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  161.261922  151.558160\n",
      "2023-12-26  161.131345  152.431893\n",
      "2023-12-27  160.841504  153.481426\n",
      "2023-12-28  160.500921  154.535983\n",
      "2023-12-29  160.405903  155.116388\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  65.720211\n",
      "2023-12-26  66.890119\n",
      "2023-12-27  67.161000\n",
      "2023-12-28  67.480248\n",
      "2023-12-29  67.015445\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  28.644801\n",
      "2023-12-26  28.812194\n",
      "2023-12-27  28.999145\n",
      "2023-12-28  29.204513\n",
      "2023-12-29  29.311333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    153.707834    145.258489\n",
      "2023-12-26    154.167929    145.655411\n",
      "2023-12-27    154.665961    146.048372\n",
      "2023-12-28    155.098495    146.452606\n",
      "2023-12-29    155.454186    146.842697\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.671324\n",
      "2023-12-26  1.934359\n",
      "2023-12-27  2.138862\n",
      "2023-12-28  2.245586\n",
      "2023-12-29  2.292590\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  47.362069  40.438039\n",
      "2023-12-26  48.528518  39.905106\n",
      "2023-12-27  49.539717  39.538276\n",
      "2023-12-28  50.293103  39.322688\n",
      "2023-12-29  50.934575  39.228881\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  66.096401\n",
      "2023-12-26  69.625522\n",
      "2023-12-27  69.961913\n",
      "2023-12-28  68.839575\n",
      "2023-12-29  68.409991\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  25.610192\n",
      "2023-12-26  26.385538\n",
      "2023-12-27  27.200672\n",
      "2023-12-28  27.980741\n",
      "2023-12-29  28.631002\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     43.090891     39.303954\n",
      "2023-12-26     43.473763     39.551744\n",
      "2023-12-27     43.885910     39.805285\n",
      "2023-12-28     44.247073     40.048971\n",
      "2023-12-29     44.564160     40.286420\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.862656\n",
      "2023-12-26  0.879688\n",
      "2023-12-27  0.899501\n",
      "2023-12-28  0.922835\n",
      "2023-12-29  0.943167\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  156.900586  148.823097\n",
      "2023-12-26  156.727070  149.475085\n",
      "2023-12-27  156.519242  150.147601\n",
      "2023-12-28  156.296985  150.809934\n",
      "2023-12-29  156.351635  150.960062\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  51.865475\n",
      "2023-12-26  52.837202\n",
      "2023-12-27  53.139441\n",
      "2023-12-28  53.477198\n",
      "2023-12-29  53.717293\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  18.473561\n",
      "2023-12-26  18.300921\n",
      "2023-12-27  18.112726\n",
      "2023-12-28  17.840204\n",
      "2023-12-29  17.577808\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    150.755808    150.082421\n",
      "2023-12-26    151.085940    150.109123\n",
      "2023-12-27    151.410592    150.149038\n",
      "2023-12-28    151.741816    150.189634\n",
      "2023-12-29    152.041176    150.229926\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  4.577072\n",
      "2023-12-26  4.590490\n",
      "2023-12-27  4.627862\n",
      "2023-12-28  4.674954\n",
      "2023-12-29  4.642896\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  167.293760  147.903150\n",
      "2023-12-26  168.049965  148.640593\n",
      "2023-12-27  168.808518  149.440542\n",
      "2023-12-28  169.586812  150.232541\n",
      "2023-12-29  170.278038  150.919008\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  71.112214\n",
      "2023-12-26  71.960606\n",
      "2023-12-27  72.803546\n",
      "2023-12-28  73.536911\n",
      "2023-12-29  73.083903\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  26.875170\n",
      "2023-12-26  27.728324\n",
      "2023-12-27  28.589883\n",
      "2023-12-28  29.483525\n",
      "2023-12-29  30.348901\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    154.453934    147.561201\n",
      "2023-12-26    155.173244    147.961345\n",
      "2023-12-27    155.946927    148.398352\n",
      "2023-12-28    156.662960    148.867333\n",
      "2023-12-29    157.329860    149.322633\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  4.794528\n",
      "2023-12-26  4.727765\n",
      "2023-12-27  4.754766\n",
      "2023-12-28  4.823400\n",
      "2023-12-29  4.875009\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  292.329199  275.310938\n",
      "2023-12-26  292.631305  276.263373\n",
      "2023-12-27  293.056554  277.235069\n",
      "2023-12-28  293.109154  278.874787\n",
      "2023-12-29  293.555466  279.877768\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  62.263781\n",
      "2023-12-26  63.019560\n",
      "2023-12-27  64.103092\n",
      "2023-12-28  64.914854\n",
      "2023-12-29  65.336028\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  19.558127\n",
      "2023-12-26  19.605462\n",
      "2023-12-27  19.738978\n",
      "2023-12-28  19.966301\n",
      "2023-12-29  20.206065\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    279.388281    266.132828\n",
      "2023-12-26    280.266384    266.643077\n",
      "2023-12-27    281.153984    267.274285\n",
      "2023-12-28    282.009103    267.980090\n",
      "2023-12-29    282.922295    268.675323\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  1.162204\n",
      "2023-12-26  1.246474\n",
      "2023-12-27  1.325871\n",
      "2023-12-28  1.435218\n",
      "2023-12-29  1.524232\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  107.214185   98.476909\n",
      "2023-12-26  107.517581   98.857967\n",
      "2023-12-27  107.553967   99.663194\n",
      "2023-12-28  107.749198  100.294446\n",
      "2023-12-29  108.067146  100.695282\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.598253\n",
      "2023-12-26  57.439172\n",
      "2023-12-27  58.038689\n",
      "2023-12-28  59.374874\n",
      "2023-12-29  59.793991\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22   9.799121\n",
      "2023-12-26  10.042278\n",
      "2023-12-27  10.241374\n",
      "2023-12-28  10.554195\n",
      "2023-12-29  10.878080\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    101.892650    101.573441\n",
      "2023-12-26    102.122109    101.662673\n",
      "2023-12-27    102.327788    101.764205\n",
      "2023-12-28    102.569285    101.891491\n",
      "2023-12-29    102.845819    102.016355\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.831574\n",
      "2023-12-26  2.792836\n",
      "2023-12-27  2.683764\n",
      "2023-12-28  2.663895\n",
      "2023-12-29  2.678377\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  379.890269  364.446209\n",
      "2023-12-26  379.360852  364.582068\n",
      "2023-12-27  377.586850  365.496212\n",
      "2023-12-28  376.887719  365.839643\n",
      "2023-12-29  376.222291  366.219116\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.948831\n",
      "2023-12-26  57.982270\n",
      "2023-12-27  57.632764\n",
      "2023-12-28  58.167712\n",
      "2023-12-29  58.508125\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  21.974784\n",
      "2023-12-26  22.020208\n",
      "2023-12-27  22.026955\n",
      "2023-12-28  22.081749\n",
      "2023-12-29  22.158986\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    371.855002    352.323810\n",
      "2023-12-26    372.045598    353.312688\n",
      "2023-12-27    372.315701    354.191505\n",
      "2023-12-28    372.507002    355.229788\n",
      "2023-12-29    372.718561    356.188384\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  2.966104\n",
      "2023-12-26  1.977977\n",
      "2023-12-27  1.110793\n",
      "2023-12-28  0.552530\n",
      "2023-12-29  0.089053\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  125.468352  105.254719\n",
      "2023-12-26  125.419692  105.345289\n",
      "2023-12-27  125.563684  105.076720\n",
      "2023-12-28  125.657068  104.866247\n",
      "2023-12-29  125.762512  104.628792\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  48.146751\n",
      "2023-12-26  48.126516\n",
      "2023-12-27  47.213444\n",
      "2023-12-28  49.110044\n",
      "2023-12-29  48.841502\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  21.352998\n",
      "2023-12-26  20.741573\n",
      "2023-12-27  20.196659\n",
      "2023-12-28  19.605099\n",
      "2023-12-29  18.988368\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    112.054397    106.165203\n",
      "2023-12-26    112.129370    106.375639\n",
      "2023-12-27    112.237877    106.588830\n",
      "2023-12-28    112.351189    106.821239\n",
      "2023-12-29    112.387973    107.036323\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -1.395525\n",
      "2023-12-26 -1.291613\n",
      "2023-12-27 -1.186085\n",
      "2023-12-28 -1.115727\n",
      "2023-12-29 -0.984473\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  151.104488  138.688053\n",
      "2023-12-26  150.662980  138.609394\n",
      "2023-12-27  149.953354  138.707579\n",
      "2023-12-28  149.402471  138.728482\n",
      "2023-12-29  148.115903  139.330000\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  45.362424\n",
      "2023-12-26  46.403911\n",
      "2023-12-27  46.595397\n",
      "2023-12-28  46.126599\n",
      "2023-12-29  47.468581\n",
      "After ADX:                dx_30\n",
      "Date                \n",
      "2023-12-22  9.989554\n",
      "2023-12-26  9.914700\n",
      "2023-12-27  9.825308\n",
      "2023-12-28  9.773187\n",
      "2023-12-29  9.603948\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    146.114411    145.248704\n",
      "2023-12-26    145.935460    145.264977\n",
      "2023-12-27    145.726084    145.294104\n",
      "2023-12-28    145.517036    145.312956\n",
      "2023-12-29    145.357388    145.337255\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-22  11.093812\n",
      "2023-12-26  10.870213\n",
      "2023-12-27  10.610925\n",
      "2023-12-28  10.196176\n",
      "2023-12-29   9.560948\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  276.087092  227.358585\n",
      "2023-12-26  275.287562  232.289279\n",
      "2023-12-27  273.201073  238.543829\n",
      "2023-12-28  270.546866  244.710971\n",
      "2023-12-29  270.910589  245.468039\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  70.397004\n",
      "2023-12-26  70.294637\n",
      "2023-12-27  70.479672\n",
      "2023-12-28  69.459232\n",
      "2023-12-29  67.301722\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  28.843087\n",
      "2023-12-26  29.445653\n",
      "2023-12-27  30.039490\n",
      "2023-12-28  30.606751\n",
      "2023-12-29  30.976245\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    241.266462    222.681870\n",
      "2023-12-26    243.014453    223.736183\n",
      "2023-12-27    244.724222    224.783349\n",
      "2023-12-28    246.199994    225.876052\n",
      "2023-12-29    247.653165    226.894302\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.451946\n",
      "2023-12-26  3.476579\n",
      "2023-12-27  3.577158\n",
      "2023-12-28  3.671298\n",
      "2023-12-29  3.794879\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  185.985504  174.811400\n",
      "2023-12-26  186.456501  175.277009\n",
      "2023-12-27  186.783211  176.212831\n",
      "2023-12-28  187.100647  177.169148\n",
      "2023-12-29  188.018337  177.326840\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  63.951916\n",
      "2023-12-26  65.071496\n",
      "2023-12-27  66.353621\n",
      "2023-12-28  66.936263\n",
      "2023-12-29  67.876425\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  16.493753\n",
      "2023-12-26  16.890550\n",
      "2023-12-27  17.362056\n",
      "2023-12-28  17.896022\n",
      "2023-12-29  18.467588\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    176.862166    169.584116\n",
      "2023-12-26    177.458419    169.991430\n",
      "2023-12-27    178.071039    170.441079\n",
      "2023-12-28    178.782630    170.924616\n",
      "2023-12-29    179.504940    171.401361\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -3.984858\n",
      "2023-12-26 -4.484649\n",
      "2023-12-27 -4.606741\n",
      "2023-12-28 -4.482945\n",
      "2023-12-29 -4.210650\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  556.882605  511.201431\n",
      "2023-12-26  557.078337  508.852178\n",
      "2023-12-27  557.080895  507.272325\n",
      "2023-12-28  557.143434  506.390395\n",
      "2023-12-29  555.290848  505.801007\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  46.408365\n",
      "2023-12-26  46.297413\n",
      "2023-12-27  47.575760\n",
      "2023-12-28  48.544492\n",
      "2023-12-29  49.266049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  15.057547\n",
      "2023-12-26  15.119187\n",
      "2023-12-27  15.111571\n",
      "2023-12-28  14.921791\n",
      "2023-12-29  14.724275\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    534.098843    527.848743\n",
      "2023-12-26    533.459423    528.138934\n",
      "2023-12-27    532.866440    528.303739\n",
      "2023-12-28    532.412743    528.587449\n",
      "2023-12-29    532.078498    528.878165\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  0.335397\n",
      "2023-12-26  0.305032\n",
      "2023-12-27  0.264853\n",
      "2023-12-28  0.244028\n",
      "2023-12-29  0.240881\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  36.917819  35.066623\n",
      "2023-12-26  36.914054  35.082766\n",
      "2023-12-27  36.919430  35.062156\n",
      "2023-12-28  36.915352  35.040526\n",
      "2023-12-29  36.854980  35.040911\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  57.780100\n",
      "2023-12-26  57.720500\n",
      "2023-12-27  56.692927\n",
      "2023-12-28  57.521290\n",
      "2023-12-29  58.479749\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  22.217499\n",
      "2023-12-26  21.933355\n",
      "2023-12-27  21.603934\n",
      "2023-12-28  21.385516\n",
      "2023-12-29  21.189671\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     35.565494     33.454810\n",
      "2023-12-26     35.621671     33.546017\n",
      "2023-12-27     35.668962     33.644625\n",
      "2023-12-28     35.720061     33.742672\n",
      "2023-12-29     35.774017     33.850887\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22  3.065393\n",
      "2023-12-26  2.939801\n",
      "2023-12-27  2.789657\n",
      "2023-12-28  2.756830\n",
      "2023-12-29  2.695728\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-22  260.188636  250.683264\n",
      "2023-12-26  260.359126  251.011913\n",
      "2023-12-27  260.296948  251.669677\n",
      "2023-12-28  260.520951  252.059159\n",
      "2023-12-29  260.815841  252.129180\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  59.956970\n",
      "2023-12-26  60.558161\n",
      "2023-12-27  60.263263\n",
      "2023-12-28  61.502714\n",
      "2023-12-29  61.435291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  17.120703\n",
      "2023-12-26  17.359886\n",
      "2023-12-27  17.566841\n",
      "2023-12-28  17.848365\n",
      "2023-12-29  18.153372\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22    252.927660    243.690333\n",
      "2023-12-26    253.388685    244.181496\n",
      "2023-12-27    253.861309    244.648010\n",
      "2023-12-28    254.307419    245.179565\n",
      "2023-12-29    254.713095    245.670439\n",
      "After dropping NaN values: (2487, 15)\n",
      "Initial data shape: (2516, 8)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-22 -0.319304\n",
      "2023-12-26 -0.243216\n",
      "2023-12-27 -0.142009\n",
      "2023-12-28 -0.069285\n",
      "2023-12-29 -0.009405\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-22  52.238773  49.776829\n",
      "2023-12-26  52.251080  49.771808\n",
      "2023-12-27  52.236280  49.780882\n",
      "2023-12-28  52.356325  49.729283\n",
      "2023-12-29  52.485821  49.683747\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-22  49.341277\n",
      "2023-12-26  49.037735\n",
      "2023-12-27  50.949645\n",
      "2023-12-28  50.536043\n",
      "2023-12-29  50.642997\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-22  13.616418\n",
      "2023-12-26  13.276956\n",
      "2023-12-27  12.843049\n",
      "2023-12-28  12.447747\n",
      "2023-12-29  12.038234\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-22     51.646541     52.429363\n",
      "2023-12-26     51.545403     52.413206\n",
      "2023-12-27     51.444105     52.404226\n",
      "2023-12-28     51.339716     52.399087\n",
      "2023-12-29     51.212792     52.383890\n",
      "After dropping NaN values: (2487, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.600801\n",
      "2024-01-02  2.622922\n",
      "2024-01-03  2.466367\n",
      "2024-01-04  2.340362\n",
      "2024-01-05  2.242336\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  90.143257  81.536343\n",
      "2024-01-02  90.422451  82.086188\n",
      "2024-01-03  90.586748  82.277194\n",
      "2024-01-04  90.626481  82.766738\n",
      "2024-01-05  90.743668  83.123288\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  65.326090\n",
      "2024-01-02  66.053699\n",
      "2024-01-03  61.700665\n",
      "2024-01-04  62.144418\n",
      "2024-01-05  62.639355\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  19.115495\n",
      "2024-01-02  19.480933\n",
      "2024-01-03  19.586649\n",
      "2024-01-04  19.688841\n",
      "2024-01-05  19.763549\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     83.485141     78.102363\n",
      "2024-01-02     83.874203     78.422689\n",
      "2024-01-03     84.213170     78.705291\n",
      "2024-01-04     84.572284     78.984355\n",
      "2024-01-05     84.969786     79.247827\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  6.612270\n",
      "2024-01-02  6.549293\n",
      "2024-01-03  6.268038\n",
      "2024-01-04  6.088842\n",
      "2024-01-05  6.031293\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  190.974155  162.058772\n",
      "2024-01-02  192.181982  162.292486\n",
      "2024-01-03  192.926342  162.843037\n",
      "2024-01-04  193.601488  163.858566\n",
      "2024-01-05  193.991336  165.664299\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  68.874685\n",
      "2024-01-02  69.447096\n",
      "2024-01-03  66.838361\n",
      "2024-01-04  67.735903\n",
      "2024-01-05  68.912798\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  25.741996\n",
      "2024-01-02  26.185887\n",
      "2024-01-03  26.562852\n",
      "2024-01-04  26.980398\n",
      "2024-01-05  27.429610\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    171.966114    160.172064\n",
      "2024-01-02    172.932425    160.852709\n",
      "2024-01-03    173.717099    161.463671\n",
      "2024-01-04    174.506217    162.106413\n",
      "2024-01-05    175.410468    162.746120\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 22ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  4.683726\n",
      "2024-01-02  5.575137\n",
      "2024-01-03  6.469363\n",
      "2024-01-04  7.291161\n",
      "2024-01-05  7.838568\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  285.149305  261.135830\n",
      "2024-01-02  288.950718  259.791616\n",
      "2024-01-03  292.898146  258.617650\n",
      "2024-01-04  296.665220  258.032921\n",
      "2024-01-05  299.577886  258.435605\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  61.239201\n",
      "2024-01-02  65.504173\n",
      "2024-01-03  66.833746\n",
      "2024-01-04  67.798667\n",
      "2024-01-05  67.659067\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  12.810566\n",
      "2024-01-02  13.507988\n",
      "2024-01-03  14.257864\n",
      "2024-01-04  15.034957\n",
      "2024-01-05  15.786146\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    269.408817    267.806922\n",
      "2024-01-02    270.341188    268.371435\n",
      "2024-01-03    271.500491    268.951196\n",
      "2024-01-04    272.742558    269.505370\n",
      "2024-01-05    274.062130    270.061477\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.782032\n",
      "2024-01-02  2.427522\n",
      "2024-01-03  2.005641\n",
      "2024-01-04  1.341140\n",
      "2024-01-05  0.858684\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  156.488309  143.159691\n",
      "2024-01-02  156.508867  143.429132\n",
      "2024-01-03  156.300798  144.000202\n",
      "2024-01-04  156.505082  143.564918\n",
      "2024-01-05  156.424907  143.717093\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  58.749686\n",
      "2024-01-02  56.343906\n",
      "2024-01-03  54.661965\n",
      "2024-01-04  50.496512\n",
      "2024-01-05  51.157972\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  14.157813\n",
      "2024-01-02  13.917954\n",
      "2024-01-03  13.681166\n",
      "2024-01-04  13.327290\n",
      "2024-01-05  12.985209\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    148.504667    140.834000\n",
      "2024-01-02    148.741333    141.233500\n",
      "2024-01-03    148.851000    141.575333\n",
      "2024-01-04    148.799000    141.847167\n",
      "2024-01-05    148.843667    142.109834\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  1.568314\n",
      "2024-01-02  0.794526\n",
      "2024-01-03  0.068763\n",
      "2024-01-04 -0.686598\n",
      "2024-01-05 -1.328596\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  197.955942  189.191968\n",
      "2024-01-02  198.946282  187.643743\n",
      "2024-01-03  199.852618  186.221364\n",
      "2024-01-04  201.009481  183.917853\n",
      "2024-01-05  201.923618  181.893926\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  55.672685\n",
      "2024-01-02  47.631340\n",
      "2024-01-03  46.237536\n",
      "2024-01-04  43.995535\n",
      "2024-01-05  43.317651\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  17.425307\n",
      "2024-01-02  17.155195\n",
      "2024-01-03  16.923867\n",
      "2024-01-04  16.860297\n",
      "2024-01-05  16.841818\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    192.218931    184.408858\n",
      "2024-01-02    192.083776    184.590836\n",
      "2024-01-03    191.903128    184.706954\n",
      "2024-01-04    191.586331    184.759347\n",
      "2024-01-05    191.272189    184.809568\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-29  11.748438\n",
      "2024-01-02  10.419541\n",
      "2024-01-03   8.633431\n",
      "2024-01-04   7.217835\n",
      "2024-01-05   6.350370\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  274.212016  230.035985\n",
      "2024-01-02  273.465130  232.571871\n",
      "2024-01-03  272.652960  234.288042\n",
      "2024-01-04  271.524622  236.494380\n",
      "2024-01-05  270.480577  238.749425\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  71.299556\n",
      "2024-01-02  63.735260\n",
      "2024-01-03  58.110096\n",
      "2024-01-04  58.605984\n",
      "2024-01-05  60.512107\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  32.326469\n",
      "2024-01-02  32.227259\n",
      "2024-01-03  31.745011\n",
      "2024-01-04  31.278837\n",
      "2024-01-05  30.890549\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    241.024667    215.169334\n",
      "2024-01-02    242.530000    216.260501\n",
      "2024-01-03    243.725667    217.202667\n",
      "2024-01-04    244.633334    218.143501\n",
      "2024-01-05    245.657667    219.068001\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 42ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-29  11.714856\n",
      "2024-01-02  11.239584\n",
      "2024-01-03  10.076466\n",
      "2024-01-04   9.192194\n",
      "2024-01-05   8.617622\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  306.508654  240.302132\n",
      "2024-01-02  307.650876  242.710874\n",
      "2024-01-03  307.319286  245.961263\n",
      "2024-01-04  306.770598  249.563089\n",
      "2024-01-05  306.056170  253.533141\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  66.632900\n",
      "2024-01-02  64.479441\n",
      "2024-01-03  58.885929\n",
      "2024-01-04  59.660744\n",
      "2024-01-05  60.860383\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  21.284392\n",
      "2024-01-02  21.712933\n",
      "2024-01-03  21.735826\n",
      "2024-01-04  21.757957\n",
      "2024-01-05  21.860595\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    264.239398    255.531891\n",
      "2024-01-02    265.704561    256.079281\n",
      "2024-01-03    266.732808    256.402400\n",
      "2024-01-04    267.906586    256.669006\n",
      "2024-01-05    269.207782    256.950918\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  1.200642\n",
      "2024-01-02  1.111838\n",
      "2024-01-03  1.252241\n",
      "2024-01-04  1.217507\n",
      "2024-01-05  1.156108\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  151.369041  137.443288\n",
      "2024-01-02  151.542463  137.727209\n",
      "2024-01-03  152.056133  137.944111\n",
      "2024-01-04  152.113056  138.651055\n",
      "2024-01-05  151.989300  139.545534\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  49.221978\n",
      "2024-01-02  49.619258\n",
      "2024-01-03  53.006693\n",
      "2024-01-04  50.930902\n",
      "2024-01-05  50.611687\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  17.175811\n",
      "2024-01-02  16.722257\n",
      "2024-01-03  16.190473\n",
      "2024-01-04  15.770860\n",
      "2024-01-05  15.299673\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    143.319124    146.630380\n",
      "2024-01-02    143.570808    146.422769\n",
      "2024-01-03    143.827716    146.288651\n",
      "2024-01-04    144.032719    146.054750\n",
      "2024-01-05    144.240335    145.819512\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.128619\n",
      "2024-01-02  0.158163\n",
      "2024-01-03  0.210105\n",
      "2024-01-04  0.214671\n",
      "2024-01-05  0.216586\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  50.003730  46.436349\n",
      "2024-01-02  50.109142  46.530016\n",
      "2024-01-03  50.215000  46.702579\n",
      "2024-01-04  50.189232  46.976190\n",
      "2024-01-05  50.049774  47.386919\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  49.475174\n",
      "2024-01-02  49.430678\n",
      "2024-01-03  51.214047\n",
      "2024-01-04  49.233695\n",
      "2024-01-05  49.280876\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  21.510879\n",
      "2024-01-02  21.141323\n",
      "2024-01-03  20.874658\n",
      "2024-01-04  20.616882\n",
      "2024-01-05  20.403629\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     47.777642     49.726631\n",
      "2024-01-02     47.857989     49.684994\n",
      "2024-01-03     47.960229     49.643568\n",
      "2024-01-04     48.031784     49.587450\n",
      "2024-01-05     48.118955     49.532310\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.319636\n",
      "2024-01-02  0.389906\n",
      "2024-01-03  0.451512\n",
      "2024-01-04  0.478927\n",
      "2024-01-05  0.487881\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  58.729875  56.897881\n",
      "2024-01-02  58.899066  56.844852\n",
      "2024-01-03  59.077703  56.803051\n",
      "2024-01-04  59.191309  56.797732\n",
      "2024-01-05  59.277512  56.816861\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  56.116763\n",
      "2024-01-02  59.668520\n",
      "2024-01-03  60.192810\n",
      "2024-01-04  59.058232\n",
      "2024-01-05  58.544526\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  10.115714\n",
      "2024-01-02  10.157288\n",
      "2024-01-03  10.292943\n",
      "2024-01-04  10.384715\n",
      "2024-01-05  10.256930\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     57.457206     55.715710\n",
      "2024-01-02     57.559634     55.844568\n",
      "2024-01-03     57.663076     55.963352\n",
      "2024-01-04     57.755397     56.083087\n",
      "2024-01-05     57.824255     56.182626\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.124148\n",
      "2024-01-02  0.062037\n",
      "2024-01-03  0.087308\n",
      "2024-01-04  0.019560\n",
      "2024-01-05 -0.006744\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  93.706805  89.167323\n",
      "2024-01-02  93.672809  89.045115\n",
      "2024-01-03  93.670283  89.041559\n",
      "2024-01-04  93.666547  89.051759\n",
      "2024-01-05  93.670168  89.018001\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  51.516083\n",
      "2024-01-02  52.251149\n",
      "2024-01-03  53.870369\n",
      "2024-01-04  51.764654\n",
      "2024-01-05  52.365477\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  16.726693\n",
      "2024-01-02  16.565385\n",
      "2024-01-03  16.487815\n",
      "2024-01-04  16.412830\n",
      "2024-01-05  16.340345\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     92.116609     87.939628\n",
      "2024-01-02     92.000711     88.108225\n",
      "2024-01-03     91.927909     88.257195\n",
      "2024-01-04     91.789836     88.358978\n",
      "2024-01-05     91.682227     88.461606\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m28/77\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (1180, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  1.258726\n",
      "2024-01-02  1.233709\n",
      "2024-01-03  1.145576\n",
      "2024-01-04  1.029231\n",
      "2024-01-05  0.975374\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  55.555490  48.497759\n",
      "2024-01-02  55.769137  48.579693\n",
      "2024-01-03  55.868044  48.727592\n",
      "2024-01-04  55.846623  49.046544\n",
      "2024-01-05  55.809228  49.467316\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  60.610600\n",
      "2024-01-02  61.954886\n",
      "2024-01-03  58.980199\n",
      "2024-01-04  57.194541\n",
      "2024-01-05  59.031716\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  14.532532\n",
      "2024-01-02  14.813757\n",
      "2024-01-03  14.878285\n",
      "2024-01-04  14.940661\n",
      "2024-01-05  14.979515\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     51.265715     49.420365\n",
      "2024-01-02     51.414859     49.520278\n",
      "2024-01-03     51.532900     49.602073\n",
      "2024-01-04     51.637276     49.668214\n",
      "2024-01-05     51.760534     49.736579\n",
      "After dropping NaN values: (1151, 15)\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-29  13.506993\n",
      "2024-01-02  13.377508\n",
      "2024-01-03  12.611050\n",
      "2024-01-04  11.958166\n",
      "2024-01-05  11.585154\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  395.592248  329.246582\n",
      "2024-01-02  397.600005  331.173955\n",
      "2024-01-03  398.349910  333.621898\n",
      "2024-01-04  397.936939  338.101269\n",
      "2024-01-05  397.151818  343.275538\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  68.843987\n",
      "2024-01-02  69.572529\n",
      "2024-01-03  65.495801\n",
      "2024-01-04  65.864514\n",
      "2024-01-05  66.963255\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  25.245340\n",
      "2024-01-02  25.996138\n",
      "2024-01-03  26.424630\n",
      "2024-01-04  26.877691\n",
      "2024-01-05  27.369675\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    352.261532    328.920016\n",
      "2024-01-02    354.050354    330.241413\n",
      "2024-01-03    355.542767    331.423417\n",
      "2024-01-04    357.064860    332.622382\n",
      "2024-01-05    358.847963    333.843513\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                  macd\n",
      "Date                 \n",
      "2023-12-29  10.274945\n",
      "2024-01-02   9.516693\n",
      "2024-01-03   8.277092\n",
      "2024-01-04   7.237556\n",
      "2024-01-05   6.683190\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  358.723402  312.614504\n",
      "2024-01-02  358.115921  315.735372\n",
      "2024-01-03  357.393897  317.863159\n",
      "2024-01-04  356.372153  320.374575\n",
      "2024-01-05  355.548685  322.859491\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  66.742323\n",
      "2024-01-02  65.484135\n",
      "2024-01-03  60.050960\n",
      "2024-01-04  60.216187\n",
      "2024-01-05  62.340155\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  28.276407\n",
      "2024-01-02  28.426724\n",
      "2024-01-03  28.181287\n",
      "2024-01-04  27.951980\n",
      "2024-01-05  27.763795\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    325.112108    305.236054\n",
      "2024-01-02    326.450872    306.146338\n",
      "2024-01-03    327.538083    306.926107\n",
      "2024-01-04    328.606081    307.669793\n",
      "2024-01-05    329.910380    308.421964\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  4.409475\n",
      "2024-01-02  4.346029\n",
      "2024-01-03  3.894027\n",
      "2024-01-04  3.524719\n",
      "2024-01-05  3.087089\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  209.177382  191.912761\n",
      "2024-01-02  209.832169  192.367966\n",
      "2024-01-03  209.858331  192.952198\n",
      "2024-01-04  209.707912  193.889107\n",
      "2024-01-05  209.483200  194.681674\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  67.630134\n",
      "2024-01-02  66.454523\n",
      "2024-01-03  59.696071\n",
      "2024-01-04  60.044028\n",
      "2024-01-05  58.122022\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  18.200781\n",
      "2024-01-02  18.618929\n",
      "2024-01-03  18.543283\n",
      "2024-01-04  18.445294\n",
      "2024-01-05  18.163444\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    197.278748    189.262001\n",
      "2024-01-02    197.881888    189.757195\n",
      "2024-01-03    198.321135    190.102627\n",
      "2024-01-04    198.753128    190.423672\n",
      "2024-01-05    199.158409    190.725079\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.469380\n",
      "2024-01-02  2.217820\n",
      "2024-01-03  1.886820\n",
      "2024-01-04  1.664960\n",
      "2024-01-05  1.340253\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  160.405903  155.116388\n",
      "2024-01-02  160.370311  155.244388\n",
      "2024-01-03  160.437808  155.079618\n",
      "2024-01-04  160.450880  155.014991\n",
      "2024-01-05  160.578179  154.778750\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  67.015445\n",
      "2024-01-02  62.453802\n",
      "2024-01-03  59.588293\n",
      "2024-01-04  60.603389\n",
      "2024-01-05  57.274366\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  29.311333\n",
      "2024-01-02  29.059286\n",
      "2024-01-03  28.762165\n",
      "2024-01-04  28.482565\n",
      "2024-01-05  28.001293\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    155.454186    146.842697\n",
      "2024-01-02    155.727844    147.192340\n",
      "2024-01-03    155.961620    147.511111\n",
      "2024-01-04    156.172699    147.839478\n",
      "2024-01-05    156.342924    148.141727\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.292590\n",
      "2024-01-02  2.110431\n",
      "2024-01-03  1.884625\n",
      "2024-01-04  1.672066\n",
      "2024-01-05  1.488050\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  50.934575  39.228881\n",
      "2024-01-02  51.132596  39.431495\n",
      "2024-01-03  51.156468  39.871411\n",
      "2024-01-04  51.074837  40.441500\n",
      "2024-01-05  50.825494  41.245416\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  68.409991\n",
      "2024-01-02  61.466198\n",
      "2024-01-03  59.551963\n",
      "2024-01-04  59.095054\n",
      "2024-01-05  59.131093\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  28.631002\n",
      "2024-01-02  28.704611\n",
      "2024-01-03  28.637593\n",
      "2024-01-04  28.264853\n",
      "2024-01-05  27.990884\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     44.564160     40.286420\n",
      "2024-01-02     44.710533     40.484231\n",
      "2024-01-03     44.817105     40.664790\n",
      "2024-01-04     44.887167     40.844519\n",
      "2024-01-05     44.994069     41.018512\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.943167\n",
      "2024-01-02  1.202019\n",
      "2024-01-03  1.469661\n",
      "2024-01-04  1.635902\n",
      "2024-01-05  1.786773\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  156.351635  150.960062\n",
      "2024-01-02  156.759734  150.708500\n",
      "2024-01-03  157.325270  150.348726\n",
      "2024-01-04  157.788166  150.090608\n",
      "2024-01-05  158.521441  149.801346\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  53.717293\n",
      "2024-01-02  58.219878\n",
      "2024-01-03  59.482303\n",
      "2024-01-04  58.856815\n",
      "2024-01-05  59.504654\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  17.577808\n",
      "2024-01-02  17.191994\n",
      "2024-01-03  16.819041\n",
      "2024-01-04  16.513034\n",
      "2024-01-05  16.107102\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    152.041176    150.229926\n",
      "2024-01-02    152.404211    150.296846\n",
      "2024-01-03    152.810156    150.372035\n",
      "2024-01-04    153.161953    150.426996\n",
      "2024-01-05    153.490450    150.493091\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 45ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  4.642896\n",
      "2024-01-02  4.720080\n",
      "2024-01-03  4.667970\n",
      "2024-01-04  4.663072\n",
      "2024-01-05  4.673924\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  170.278038  150.919008\n",
      "2024-01-02  171.221601  151.473024\n",
      "2024-01-03  171.911550  152.093947\n",
      "2024-01-04  172.622438  152.807622\n",
      "2024-01-05  173.055641  154.047135\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  73.083903\n",
      "2024-01-02  74.681375\n",
      "2024-01-03  72.984036\n",
      "2024-01-04  73.913801\n",
      "2024-01-05  74.601971\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  30.348901\n",
      "2024-01-02  31.259164\n",
      "2024-01-03  32.139085\n",
      "2024-01-04  33.053070\n",
      "2024-01-05  33.938021\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    157.329860    149.322633\n",
      "2024-01-02    158.005605    149.800535\n",
      "2024-01-03    158.611908    150.230122\n",
      "2024-01-04    159.240058    150.683735\n",
      "2024-01-05    159.907033    151.137108\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  4.875009\n",
      "2024-01-02  4.901658\n",
      "2024-01-03  4.657834\n",
      "2024-01-04  4.204875\n",
      "2024-01-05  3.585348\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  293.555466  279.877768\n",
      "2024-01-02  294.412953  280.114909\n",
      "2024-01-03  294.656583  280.687310\n",
      "2024-01-04  294.589563  281.268051\n",
      "2024-01-05  294.467735  281.600304\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  65.336028\n",
      "2024-01-02  65.673239\n",
      "2024-01-03  62.527157\n",
      "2024-01-04  59.574775\n",
      "2024-01-05  56.700683\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  20.206065\n",
      "2024-01-02  20.460855\n",
      "2024-01-03  20.630784\n",
      "2024-01-04  20.495228\n",
      "2024-01-05  20.067118\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    282.922295    268.675323\n",
      "2024-01-02    283.665371    269.437878\n",
      "2024-01-03    284.333292    270.222432\n",
      "2024-01-04    284.806573    270.935528\n",
      "2024-01-05    285.142157    271.577156\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  1.524232\n",
      "2024-01-02  1.909130\n",
      "2024-01-03  2.309491\n",
      "2024-01-04  2.773354\n",
      "2024-01-05  3.121722\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  108.067146  100.695282\n",
      "2024-01-02  109.589102  100.212849\n",
      "2024-01-03  111.295753   99.539942\n",
      "2024-01-04  113.309201   98.666764\n",
      "2024-01-05  114.974773   98.221047\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  59.793991\n",
      "2024-01-02  65.931608\n",
      "2024-01-03  67.776539\n",
      "2024-01-04  70.219125\n",
      "2024-01-05  70.436459\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  10.878080\n",
      "2024-01-02  11.611922\n",
      "2024-01-03  12.531226\n",
      "2024-01-04  13.545116\n",
      "2024-01-05  14.525209\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    102.845819    102.016355\n",
      "2024-01-02    103.240380    102.187321\n",
      "2024-01-03    103.693164    102.378898\n",
      "2024-01-04    104.189302    102.597220\n",
      "2024-01-05    104.707718    102.833545\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.678377\n",
      "2024-01-02  2.248281\n",
      "2024-01-03  1.864231\n",
      "2024-01-04  1.330670\n",
      "2024-01-05  0.882372\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  376.222291  366.219116\n",
      "2024-01-02  376.011535  366.067197\n",
      "2024-01-03  375.932564  366.291633\n",
      "2024-01-04  376.089766  365.678099\n",
      "2024-01-05  376.192869  365.470379\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  58.508125\n",
      "2024-01-02  55.339104\n",
      "2024-01-03  55.177645\n",
      "2024-01-04  53.584266\n",
      "2024-01-05  53.470177\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  22.158986\n",
      "2024-01-02  21.875321\n",
      "2024-01-03  21.601112\n",
      "2024-01-04  21.267350\n",
      "2024-01-05  20.910151\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    372.718561    356.188384\n",
      "2024-01-02    372.542536    357.054499\n",
      "2024-01-03    372.567445    357.785208\n",
      "2024-01-04    372.251931    358.429320\n",
      "2024-01-05    372.075243    359.093976\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.089053\n",
      "2024-01-02 -0.435026\n",
      "2024-01-03 -1.039410\n",
      "2024-01-04 -1.638856\n",
      "2024-01-05 -2.107250\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  125.762512  104.628792\n",
      "2024-01-02  126.151775  103.551684\n",
      "2024-01-03  126.680112  101.920612\n",
      "2024-01-04  127.218923  100.080553\n",
      "2024-01-05  127.516255   98.390659\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  48.841502\n",
      "2024-01-02  46.706691\n",
      "2024-01-03  44.222095\n",
      "2024-01-04  42.597095\n",
      "2024-01-05  42.393335\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  18.988368\n",
      "2024-01-02  18.518448\n",
      "2024-01-03  18.241346\n",
      "2024-01-04  18.088908\n",
      "2024-01-05  17.968312\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    112.387973    107.036323\n",
      "2024-01-02    112.364849    107.219639\n",
      "2024-01-03    112.313089    107.339670\n",
      "2024-01-04    112.191889    107.434709\n",
      "2024-01-05    112.055826    107.513908\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29 -0.984473\n",
      "2024-01-02 -0.698175\n",
      "2024-01-03 -0.536374\n",
      "2024-01-04 -0.340078\n",
      "2024-01-05 -0.278711\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  148.115903  139.330000\n",
      "2024-01-02  147.096526  139.964651\n",
      "2024-01-03  145.876666  140.770342\n",
      "2024-01-04  146.191461  140.641040\n",
      "2024-01-05  146.276324  140.631747\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  47.468581\n",
      "2024-01-02  50.904773\n",
      "2024-01-03  49.533582\n",
      "2024-01-04  50.768246\n",
      "2024-01-05  48.889306\n",
      "After ADX:                dx_30\n",
      "Date                \n",
      "2023-12-29  9.603948\n",
      "2024-01-02  9.409162\n",
      "2024-01-03  9.220870\n",
      "2024-01-04  9.046758\n",
      "2024-01-05  8.759375\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    145.357388    145.337255\n",
      "2024-01-02    145.223584    145.432814\n",
      "2024-01-03    145.117915    145.508938\n",
      "2024-01-04    145.064916    145.610177\n",
      "2024-01-05    144.993271    145.668214\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  9.560948\n",
      "2024-01-02  8.396700\n",
      "2024-01-03  7.047605\n",
      "2024-01-04  5.862581\n",
      "2024-01-05  4.857787\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  270.910589  245.468039\n",
      "2024-01-02  270.763973  245.228761\n",
      "2024-01-03  270.683932  245.426463\n",
      "2024-01-04  270.668302  245.464031\n",
      "2024-01-05  270.490325  245.840438\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  67.301722\n",
      "2024-01-02  61.613770\n",
      "2024-01-03  58.484567\n",
      "2024-01-04  58.057957\n",
      "2024-01-05  57.970456\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  30.976245\n",
      "2024-01-02  30.803109\n",
      "2024-01-03  30.528856\n",
      "2024-01-04  30.162341\n",
      "2024-01-05  29.852604\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    247.653165    226.894302\n",
      "2024-01-02    248.805863    227.793726\n",
      "2024-01-03    249.823614    228.532941\n",
      "2024-01-04    250.691461    229.264512\n",
      "2024-01-05    251.582242    229.999739\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  3.794879\n",
      "2024-01-02  3.921942\n",
      "2024-01-03  3.967315\n",
      "2024-01-04  4.055636\n",
      "2024-01-05  4.120497\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  188.018337  177.326840\n",
      "2024-01-02  189.091629  177.287071\n",
      "2024-01-03  190.003946  177.277185\n",
      "2024-01-04  191.065289  177.194802\n",
      "2024-01-05  192.039859  177.303905\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  67.876425\n",
      "2024-01-02  68.616540\n",
      "2024-01-03  68.406141\n",
      "2024-01-04  69.408742\n",
      "2024-01-05  69.832050\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  18.467588\n",
      "2024-01-02  19.126374\n",
      "2024-01-03  19.845870\n",
      "2024-01-04  20.554317\n",
      "2024-01-05  21.239150\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    179.504940    171.401361\n",
      "2024-01-02    180.187354    171.870802\n",
      "2024-01-03    180.861536    172.353531\n",
      "2024-01-04    181.567466    172.851642\n",
      "2024-01-05    182.193696    173.375415\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29 -4.210650\n",
      "2024-01-02 -2.931008\n",
      "2024-01-03 -1.682198\n",
      "2024-01-04 -0.416393\n",
      "2024-01-05 -0.056066\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  555.290848  505.801007\n",
      "2024-01-02  554.365644  505.950576\n",
      "2024-01-03  553.500410  506.195895\n",
      "2024-01-04  552.699399  506.516840\n",
      "2024-01-05  551.058131  506.952986\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  49.266049\n",
      "2024-01-02  54.658288\n",
      "2024-01-03  55.676859\n",
      "2024-01-04  56.937975\n",
      "2024-01-05  53.222580\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  14.724275\n",
      "2024-01-02  14.331861\n",
      "2024-01-03  14.166419\n",
      "2024-01-04  14.069211\n",
      "2024-01-05  13.668784\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    532.078498    528.878165\n",
      "2024-01-02    532.123308    529.289213\n",
      "2024-01-03    532.373369    529.603374\n",
      "2024-01-04    532.774718    529.945567\n",
      "2024-01-05    532.762304    530.192250\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 41ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  0.240881\n",
      "2024-01-02  0.325299\n",
      "2024-01-03  0.408999\n",
      "2024-01-04  0.485866\n",
      "2024-01-05  0.603595\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  36.854980  35.040911\n",
      "2024-01-02  36.925596  34.998860\n",
      "2024-01-03  37.135473  34.895626\n",
      "2024-01-04  37.331475  34.790079\n",
      "2024-01-05  37.722643  34.560778\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  58.479749\n",
      "2024-01-02  63.294122\n",
      "2024-01-03  64.309975\n",
      "2024-01-04  65.060180\n",
      "2024-01-05  67.825489\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  21.189671\n",
      "2024-01-02  21.407506\n",
      "2024-01-03  21.822461\n",
      "2024-01-04  22.256620\n",
      "2024-01-05  22.803099\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     35.774017     33.850887\n",
      "2024-01-02     35.859712     33.973478\n",
      "2024-01-03     35.952707     34.105353\n",
      "2024-01-04     36.036497     34.231038\n",
      "2024-01-05     36.130126     34.364976\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29  2.695728\n",
      "2024-01-02  2.499744\n",
      "2024-01-03  2.247116\n",
      "2024-01-04  2.152864\n",
      "2024-01-05  2.060835\n",
      "After Bollinger Bands:                boll_ub     boll_lb\n",
      "Date                              \n",
      "2023-12-29  260.815841  252.129180\n",
      "2024-01-02  260.898197  252.287443\n",
      "2024-01-03  260.745954  252.791668\n",
      "2024-01-04  260.669120  253.365648\n",
      "2024-01-05  260.423145  254.148547\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  61.435291\n",
      "2024-01-02  59.439884\n",
      "2024-01-03  58.262701\n",
      "2024-01-04  59.772111\n",
      "2024-01-05  59.845884\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  18.153372\n",
      "2024-01-02  18.222687\n",
      "2024-01-03  18.202188\n",
      "2024-01-04  18.339751\n",
      "2024-01-05  18.501961\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29    254.713095    245.670439\n",
      "2024-01-02    255.054471    246.099414\n",
      "2024-01-03    255.333538    246.487843\n",
      "2024-01-04    255.653039    246.913205\n",
      "2024-01-05    255.900288    247.304175\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (2491, 15)\n",
      "After MACD:                 macd\n",
      "Date                \n",
      "2023-12-29 -0.009405\n",
      "2024-01-02  0.080928\n",
      "2024-01-03  0.151043\n",
      "2024-01-04  0.163585\n",
      "2024-01-05  0.143818\n",
      "After Bollinger Bands:               boll_ub    boll_lb\n",
      "Date                            \n",
      "2023-12-29  52.485821  49.683747\n",
      "2024-01-02  52.746854  49.605493\n",
      "2024-01-03  52.972604  49.564173\n",
      "2024-01-04  53.066236  49.556823\n",
      "2024-01-05  53.120494  49.609826\n",
      "After RSI:                rsi_30\n",
      "Date                 \n",
      "2023-12-29  50.642997\n",
      "2024-01-02  52.807254\n",
      "2024-01-03  52.820291\n",
      "2024-01-04  50.591648\n",
      "2024-01-05  49.129567\n",
      "After ADX:                 dx_30\n",
      "Date                 \n",
      "2023-12-29  12.038234\n",
      "2024-01-02  11.791828\n",
      "2024-01-03  11.633732\n",
      "2024-01-04  11.312952\n",
      "2024-01-05  11.073096\n",
      "After SMA:             close_30_sma  close_60_sma\n",
      "Date                                  \n",
      "2023-12-29     51.212792     52.383890\n",
      "2024-01-02     51.255028     52.388297\n",
      "2024-01-03     51.304961     52.407436\n",
      "2024-01-04     51.338449     52.421212\n",
      "2024-01-05     51.354193     52.419519\n",
      "After dropping NaN values: (2462, 15)\n",
      "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 38ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Error processing future data for MMM: 'function' object is not subscriptable\n",
      "Error processing future data for AXP: 'function' object is not subscriptable\n",
      "Error processing future data for AMGN: 'function' object is not subscriptable\n",
      "Error processing future data for AMZN: 'function' object is not subscriptable\n",
      "Error processing future data for AAPL: 'function' object is not subscriptable\n",
      "Error processing future data for BA: 'function' object is not subscriptable\n",
      "Error processing future data for CAT: 'function' object is not subscriptable\n",
      "Error processing future data for CVX: 'function' object is not subscriptable\n",
      "Error processing future data for CSCO: 'function' object is not subscriptable\n",
      "Error processing future data for KO: 'function' object is not subscriptable\n",
      "Error processing future data for DIS: 'function' object is not subscriptable\n",
      "Error processing future data for DOW: 'function' object is not subscriptable\n",
      "Error processing future data for GS: 'function' object is not subscriptable\n",
      "Error processing future data for HD: 'function' object is not subscriptable\n",
      "Error processing future data for HON: 'function' object is not subscriptable\n",
      "Error processing future data for IBM: 'function' object is not subscriptable\n",
      "Error processing future data for INTC: 'function' object is not subscriptable\n",
      "Error processing future data for JNJ: 'function' object is not subscriptable\n",
      "Error processing future data for JPM: 'function' object is not subscriptable\n",
      "Error processing future data for MCD: 'function' object is not subscriptable\n",
      "Error processing future data for MRK: 'function' object is not subscriptable\n",
      "Error processing future data for MSFT: 'function' object is not subscriptable\n",
      "Error processing future data for NKE: 'function' object is not subscriptable\n",
      "Error processing future data for PG: 'function' object is not subscriptable\n",
      "Error processing future data for CRM: 'function' object is not subscriptable\n",
      "Error processing future data for TRV: 'function' object is not subscriptable\n",
      "Error processing future data for UNH: 'function' object is not subscriptable\n",
      "Error processing future data for VZ: 'function' object is not subscriptable\n",
      "Error processing future data for V: 'function' object is not subscriptable\n",
      "Error processing future data for WMT: 'function' object is not subscriptable\n",
      "Portfolio History:\n",
      "Week 1: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 2: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 3: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 4: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 5: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 6: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 7: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 8: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 9: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 10: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 11: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 12: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 13: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 14: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 15: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 16: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 17: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 18: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 19: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 20: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 21: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 22: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 23: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 24: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 25: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 26: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 27: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 28: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 29: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Week 30: {'MMM': 33513.790144721934, 'AXP': 33327.99517294209, 'AMGN': 32947.85200817517, 'AMZN': 34601.52799495436, 'AAPL': 33799.46393161262, 'BA': 31969.219047662493, 'CAT': 32877.24041531971, 'CVX': 32793.48347182662, 'CSCO': 33548.147483953566, 'KO': 33443.58530505277, 'DIS': 32240.337152774267, 'DOW': 31823.38662607878, 'GS': 32651.522808376056, 'HD': 34533.02619666336, 'HON': 34401.88440768207, 'IBM': 32691.095711828293, 'INTC': 32956.393825087485, 'JNJ': 33431.055786342054, 'JPM': 32389.680196484598, 'MCD': 34408.16817419566, 'MRK': 32002.3143115871, 'MSFT': 34293.1292496739, 'NKE': 33260.93411724556, 'PG': 33927.7014268151, 'CRM': 33340.01149838037, 'TRV': 35373.526535394674, 'UNH': 33986.463957224776, 'VZ': 32249.58983740469, 'V': 34491.643811746835, 'WMT': 32725.829392793046}\n",
      "Weekly Returns:\n",
      "Week 1: $0.00\n",
      "Week 2: $0.00\n",
      "Week 3: $0.00\n",
      "Week 4: $0.00\n",
      "Week 5: $0.00\n",
      "Week 6: $0.00\n",
      "Week 7: $0.00\n",
      "Week 8: $0.00\n",
      "Week 9: $0.00\n",
      "Week 10: $0.00\n",
      "Week 11: $0.00\n",
      "Week 12: $0.00\n",
      "Week 13: $0.00\n",
      "Week 14: $0.00\n",
      "Week 15: $0.00\n",
      "Week 16: $0.00\n",
      "Week 17: $0.00\n",
      "Week 18: $0.00\n",
      "Week 19: $0.00\n",
      "Week 20: $0.00\n",
      "Week 21: $0.00\n",
      "Week 22: $0.00\n",
      "Week 23: $0.00\n",
      "Week 24: $0.00\n",
      "Week 25: $0.00\n",
      "Week 26: $0.00\n",
      "Week 27: $0.00\n",
      "Week 28: $0.00\n",
      "Week 29: $0.00\n",
      "Week 30: $0.00\n"
     ]
    }
   ],
   "source": [
    "## Step 8 - Portfolio Construction\n",
    "def initialize_portfolio(initial_date, models, scalers, tickers, start_date, end_date, initial_investment):\n",
    "    historical_data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = load_stock_data(ticker, start_date, end_date)\n",
    "            historical_data[ticker] = feature_engineering(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {ticker}: {e}\")\n",
    "    \n",
    "    predictions = generate_predictions(models, scalers, tickers, historical_data, initial_date)\n",
    "    signals = generate_trading_signals(predictions)\n",
    "    allocations = allocate_portfolio(signals, initial_investment)\n",
    "    return allocations, predictions\n",
    "\n",
    "\n",
    "# Rebalance Portfolio Weekly\n",
    "def rebalance_portfolio(start_date, end_date, initial_portfolio, initial_predictions, models, scalers, tickers, historical_data):\n",
    "    current_portfolio = initial_portfolio.copy()\n",
    "    portfolio_history = []\n",
    "    weekly_returns = []\n",
    "    \n",
    "    current_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        week_end_date = current_date + timedelta(days=7)\n",
    "        \n",
    "        predictions = generate_predictions(models, scalers, tickers, historical_data, week_end_date.strftime(\"%Y-%m-%d\"))\n",
    "        signals = generate_trading_signals(predictions)\n",
    "        \n",
    "        # Calculate portfolio returns based on new predictions\n",
    "        current_returns = 0\n",
    "        for ticker in current_portfolio.keys():\n",
    "            if ticker in signals:\n",
    "                new_signal = signals[ticker]\n",
    "                old_signal = initial_predictions[ticker]\n",
    "                \n",
    "                # Sell if direction changes or buy more if confidence increases\n",
    "                if new_signal < 0.5 and old_signal >= 0.5:\n",
    "                    current_returns += current_portfolio[ticker]  # Sell\n",
    "                    current_portfolio[ticker] = 0\n",
    "                elif new_signal > old_signal:\n",
    "                    additional_investment = current_returns * 0.1  # Reinvest 10% of returns\n",
    "                    current_portfolio[ticker] += additional_investment\n",
    "                    current_returns -= additional_investment\n",
    "        \n",
    "        weekly_returns.append(current_returns)\n",
    "        portfolio_history.append(current_portfolio.copy())\n",
    "        \n",
    "        current_date = week_end_date\n",
    "    \n",
    "    return portfolio_history, weekly_returns\n",
    "\n",
    "initial_investment = 1000000  # Example investment of $1,000,000\n",
    "simulation_start_date = \"2024-01-07\"\n",
    "simulation_end_date = \"2024-08-01\"\n",
    "\n",
    "initial_portfolio, initial_predictions = initialize_portfolio(\n",
    "    simulation_start_date,\n",
    "    models,\n",
    "    scalers,\n",
    "    dow30_tickers,\n",
    "    start_date=\"2014-01-01\",\n",
    "    end_date=\"2024-01-01\",\n",
    "    initial_investment=initial_investment\n",
    ")\n",
    "\n",
    "# Run Rebalancing\n",
    "portfolio_history, weekly_returns = rebalance_portfolio(simulation_start_date, simulation_end_date, initial_portfolio, initial_predictions, models, scalers, dow30_tickers, load_stock_data)\n",
    "\n",
    "# Print Results\n",
    "print(\"Portfolio History:\")\n",
    "for i, week in enumerate(portfolio_history):\n",
    "    print(f\"Week {i+1}: {week}\")\n",
    "\n",
    "print(\"Weekly Returns:\")\n",
    "for i, ret in enumerate(weekly_returns):\n",
    "    print(f\"Week {i+1}: ${ret:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
