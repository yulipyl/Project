{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d60358-c7ec-460b-86b5-5afa0b3eec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install keras\n",
    "# !pip install pydot\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow\n",
    "\n",
    "\n",
    "# Stock price prediction using our Keras’ LSTMs model trained on past stocks data.\n",
    "\n",
    "## Step 1 - Import the Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "## Step 2 – Reading our training data and getting our training data in shape\n",
    "\n",
    "def load_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    # data.reset_index(inplace=True)\n",
    "    data.drop(['Adj Close'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean() \n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n",
    "# Define the stock ticker and the training time frame\n",
    "stock_ticker = \"AAPL\"\n",
    "start_date = \"2010-01-01\"  # Start with a long enough historical period\n",
    "end_date = \"2023-01-01\"   \n",
    "\n",
    "# Load and prepare the training data\n",
    "dataset_train = load_stock_data(stock_ticker, start_date, end_date)\n",
    "dataset_train = feature_engineering(dataset_train)\n",
    "\n",
    "#Print the shape of Dataframe  and Check for Null Values\n",
    "print(\"Dataframe Shape: \", dataset_train.shape)\n",
    "print(\"Null Value Present: \", dataset_train.isnull().values.any())\n",
    "\n",
    "## Step 3 - Setting the Target Variable, Selecting the Features, and Scaling\n",
    "\n",
    "## Step 3 - Setting the Target Variable, Selecting the Features, and Scaling\n",
    "output_var = pd.DataFrame(dataset_train['Close'])\n",
    "features = ['Open', 'High', 'Low', 'Volume', 'SMA_10', 'SMA_50']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "feature_transform = scaler.fit_transform(dataset_train[features])\n",
    "output_var_scaled = scaler.fit_transform(output_var)  # Scaling the target variable\n",
    "\n",
    "# Convert back to DataFrame\n",
    "feature_transform = pd.DataFrame(columns=features, data=feature_transform, index=dataset_train.index)\n",
    "output_var_scaled = pd.DataFrame(columns=['Close'], data=output_var_scaled, index=dataset_train.index)\n",
    "\n",
    "\n",
    "## Step 4 - Splitting to Training set and Test set\n",
    "\n",
    "train_size = int(len(feature_transform) * 0.8)\n",
    "X_train, X_test = feature_transform[:train_size], feature_transform[train_size:]\n",
    "y_train, y_test = output_var_scaled[:train_size].values.ravel(), output_var_scaled[train_size:].values.ravel()\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "## Step 5 - Building and Training the LSTM Model\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(1, X_train.shape[2]), activation='relu', return_sequences=False))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = lstm.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1, shuffle=False)\n",
    "\n",
    "## Step 6 - Making the Prediction\n",
    "\n",
    "y_pred = lstm.predict(X_test)\n",
    "\n",
    "def predict_future_prices(model, last_known_data, days_to_predict, scaler, feature_columns):\n",
    "    predictions = []\n",
    "    current_data = last_known_data\n",
    "\n",
    "    for _ in range(days_to_predict):\n",
    "        # Predict the next day's price\n",
    "        pred = model.predict(current_data)\n",
    "        predictions.append(pred[0, 0])\n",
    "        \n",
    "        # Prepare the new data point for the next prediction\n",
    "        # Remove the first row and append the predicted value\n",
    "        current_data = np.roll(current_data, shift=-1, axis=1)\n",
    "        current_data[0, -1, 0] = pred\n",
    "\n",
    "    return predictions\n",
    "\n",
    "days_to_predict = 10\n",
    "last_known_data = np.array(feature_transform[-1:]).reshape((1, 1, len(features)))\n",
    "future_predictions = predict_future_prices(lstm, last_known_data, days_to_predict, scaler, features)\n",
    "future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "future_predictions = future_predictions.flatten()\n",
    "future_predictions\n",
    "\n",
    "## Step 7- Evaluate Model\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE on Test Set: {mse:.4f}')\n",
    "print(f'R2 Score on Test Set: {r2:.4f}')\n",
    "\n",
    "## Step 8 - Plot Predicted vs True Adj Close Value – LSTM\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare dates for plotting\n",
    "last_date = dataset_train.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=days_to_predict)\n",
    "\n",
    "# Prepare historical dates for plotting\n",
    "historical_dates = dataset_train.index\n",
    "test_dates = historical_dates[-len(y_test):]\n",
    "predicted_dates = historical_dates[-len(y_pred):]\n",
    "\n",
    "# Plot historical and predicted data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(historical_dates, dataset_train['Close'], label='Historical Data', color='blue')\n",
    "plt.plot(test_dates, scaler.inverse_transform(y_test.reshape(-1, 1)), label='True Values', color='green')\n",
    "plt.plot(predicted_dates, scaler.inverse_transform(y_pred.reshape(-1, 1)), label='LSTM Predictions', color='red')\n",
    "plt.plot(future_dates, future_predictions, linestyle='--', color='orange', label='Future Predictions')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(f'Stock Price Prediction for {stock_ticker} with Extended Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoomed-In Plot for the Last 15 Days\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Extracting the last 15 days data\n",
    "zoom_start_date = dataset_train.index[-15]\n",
    "zoom_end_date = dataset_train.index[-1]\n",
    "zoom_dates = dataset_train.index[-15:]\n",
    "zoom_true_values = scaler.inverse_transform(y_test[-15:].reshape(-1, 1))\n",
    "zoom_lstm_predictions = scaler.inverse_transform(y_pred[-15:].reshape(-1, 1))\n",
    "zoom_future_predictions = future_predictions[:15]  # Only the first 15 future days\n",
    "\n",
    "plt.plot(zoom_dates, scaler.inverse_transform(output_var_scaled.loc[zoom_dates].values), label='True Values', color='green')\n",
    "plt.plot(zoom_dates, zoom_lstm_predictions, label='LSTM Predictions', color='red')\n",
    "plt.plot(future_dates[:15], zoom_future_predictions, linestyle='--', color='orange', label='Future Predictions')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(f'Zoomed-In View: Last 15 Days with LSTM Predictions for {stock_ticker}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the last number in zoom_lstm_predictions\n",
    "last_lstm_prediction = zoom_lstm_predictions[-1]\n",
    "\n",
    "# Calculate the average of the first three numbers in zoom_future_predictions\n",
    "average_future_predictions = np.mean(zoom_future_predictions[:3])\n",
    "\n",
    "# Determine the message to output\n",
    "if last_lstm_prediction < average_future_predictions:\n",
    "    message = f\"According to the LSTM model, you should buy the {stock_ticker}\"\n",
    "elif last_lstm_prediction > average_future_predictions:\n",
    "    message = f\"According to the LSTM model, you should sell the {stock_ticker}\"\n",
    "else:\n",
    "    message = \"According to the LSTM model, the market seems to not change significantly\"\n",
    "\n",
    "print(message)\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def load_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.drop(['Adj Close'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean() \n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n",
    "def predict_future_prices(model, last_known_data, days_to_predict, scaler, feature_columns):\n",
    "    predictions = []\n",
    "    current_data = last_known_data\n",
    "\n",
    "    for _ in range(days_to_predict):\n",
    "        # Predict the next day's price\n",
    "        pred = model.predict(current_data)\n",
    "        predictions.append(pred[0, 0])\n",
    "\n",
    "        # Prepare the new data point for the next prediction\n",
    "        # Remove the first row and append the predicted value\n",
    "        current_data = np.roll(current_data, shift=-1, axis=1)\n",
    "        current_data[0, -1, 0] = pred\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Define the stock ticker and the training time frame\n",
    "stock_ticker = \"AAPL\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "\n",
    "# Load and prepare the training data\n",
    "dataset_train = load_stock_data(stock_ticker, start_date, end_date)\n",
    "dataset_train = feature_engineering(dataset_train)\n",
    "\n",
    "# Initialize the DataFrame to store the end dates and related values\n",
    "end_dates_df = pd.DataFrame(columns=[\"End Date\", \"Close\", \"Last LSTM Prediction\", \"Avg Future Predictions\"])\n",
    "\n",
    "# Start the loop to add one day until 2023-01-31\n",
    "while end_date != \"2023-01-31\":\n",
    "    # Convert end_date string to datetime object\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Increment the date by one day\n",
    "    end_date_dt += timedelta(days=1)\n",
    "    \n",
    "    # Convert back to string format\n",
    "    end_date = end_date_dt.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Load and prepare the data for the new end date\n",
    "    dataset_train = load_stock_data(stock_ticker, start_date, end_date)\n",
    "    dataset_train = feature_engineering(dataset_train)\n",
    "    \n",
    "    output_var = pd.DataFrame(dataset_train['Close'])\n",
    "    features = ['Open', 'High', 'Low', 'Volume', 'SMA_10', 'SMA_50']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    feature_transform = scaler.fit_transform(dataset_train[features])\n",
    "    output_var_scaled = scaler.fit_transform(output_var)  # Scaling the target variable\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    feature_transform = pd.DataFrame(columns=features, data=feature_transform, index=dataset_train.index)\n",
    "    output_var_scaled = pd.DataFrame(columns=['Close'], data=output_var_scaled, index=dataset_train.index)\n",
    "\n",
    "    train_size = int(len(feature_transform) * 0.8)\n",
    "    X_train, X_test = feature_transform[:train_size], feature_transform[train_size:]\n",
    "    y_train, y_test = output_var_scaled[:train_size].values.ravel(), output_var_scaled[train_size:].values.ravel()\n",
    "\n",
    "    X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(32, input_shape=(1, X_train.shape[2]), activation='relu', return_sequences=False))\n",
    "    lstm.add(Dense(1))\n",
    "    lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = lstm.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1, shuffle=False) \n",
    "    y_pred = lstm.predict(X_test)\n",
    "\n",
    "    # Predict future prices\n",
    "    days_to_predict = 10\n",
    "    last_known_data = np.array(feature_transform[-1:]).reshape((1, 1, len(features)))\n",
    "    future_predictions = predict_future_prices(lstm, last_known_data, days_to_predict, scaler, features)\n",
    "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "    future_predictions = future_predictions.flatten()\n",
    "    \n",
    "    # Prepare dates for plotting\n",
    "    last_date = dataset_train.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=days_to_predict)\n",
    "\n",
    "    # Prepare historical dates for plotting\n",
    "    historical_dates = dataset_train.index\n",
    "    test_dates = historical_dates[-len(y_test):]\n",
    "    predicted_dates = historical_dates[-len(y_pred):]\n",
    "    \n",
    "    # Extract the last 15 days data\n",
    "    zoom_start_date = dataset_train.index[-15]\n",
    "    zoom_end_date = dataset_train.index[-1]\n",
    "    zoom_dates = dataset_train.index[-15:]\n",
    "    zoom_true_values = scaler.inverse_transform(y_test[-15:].reshape(-1, 1))\n",
    "    zoom_lstm_predictions = scaler.inverse_transform(y_pred[-15:].reshape(-1, 1))\n",
    "    zoom_future_predictions = future_predictions[:15]  # Only the first 15 future days\n",
    "    \n",
    "    # Calculate the last number in zoom_lstm_predictions\n",
    "    last_lstm_prediction = zoom_lstm_predictions[-1]\n",
    "\n",
    "    # Calculate the average of the first three numbers in zoom_future_predictions\n",
    "    average_future_predictions = np.mean(zoom_future_predictions[:3])\n",
    "\n",
    "    # Record the 'Close' value, last_lstm_prediction, and average_future_predictions\n",
    "    new_row = pd.DataFrame({\n",
    "        \"End Date\": [end_date],\n",
    "        \"Close\": [dataset_train['Close'].iloc[-1]],  # Last close value in the current DataFrame\n",
    "        \"Last LSTM Prediction\": [last_lstm_prediction],\n",
    "        \"Avg Future Predictions\": [average_future_predictions]\n",
    "    })\n",
    "    end_dates_df = pd.concat([end_dates_df, new_row], ignore_index=True)\n",
    "\n",
    "# Print the DataFrame with end dates and predictions\n",
    "print(end_dates_df)\n",
    "\n",
    "\n",
    "# Convert End Date column to datetime format in end_dates_df\n",
    "end_dates_df['End Date'] = pd.to_datetime(end_dates_df['End Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert the index of dataset_train to datetime format\n",
    "dataset_train.index = pd.to_datetime(dataset_train.index, format='%Y-%m-%d')\n",
    "\n",
    "# Initialize variables for shares and money\n",
    "initial_shares = 100\n",
    "shares_on_hand = initial_shares\n",
    "money_spent = 0\n",
    "money_earned = 0\n",
    "\n",
    "# Get the closing price of the first day in dataset_train\n",
    "first_date = dataset_train.index[0]\n",
    "first_close_price = dataset_train.loc[first_date, 'Close']\n",
    "\n",
    "# Track the money spent on initial 100 shares\n",
    "initial_investment = initial_shares * first_close_price\n",
    "\n",
    "# Lists to store results for each day\n",
    "shares_on_hand_list = []\n",
    "money_spent_list = []\n",
    "money_earned_list = []\n",
    "\n",
    "# Iterate over the rows in end_dates_df\n",
    "for index, row in end_dates_df.iterrows():\n",
    "    # Use the 'Close' column from end_dates_df\n",
    "    close_price = row['Close']\n",
    "\n",
    "    action = row['action']\n",
    "\n",
    "    if action == 1:\n",
    "        # Buy one share\n",
    "        shares_on_hand += 1\n",
    "        money_spent += close_price\n",
    "    elif action == -1:\n",
    "        # Sell one share\n",
    "        shares_on_hand -= 1\n",
    "        money_earned += close_price\n",
    "    # If action == 0, do nothing\n",
    "\n",
    "    # Record the shares and money spent/earned for the day\n",
    "    shares_on_hand_list.append(shares_on_hand)\n",
    "    money_spent_list.append(money_spent)\n",
    "    money_earned_list.append(money_earned)\n",
    "\n",
    "# Add the new columns to the end_dates_df DataFrame\n",
    "end_dates_df['Shares on Hand'] = shares_on_hand_list\n",
    "end_dates_df['Money Spent'] = money_spent_list\n",
    "end_dates_df['Money Earned'] = money_earned_list\n",
    "\n",
    "# Print the DataFrame with the new columns\n",
    "print(end_dates_df)\n",
    "\n",
    "# Get the closing price of the last day in dataset_train\n",
    "last_date = dataset_train.index[-1]\n",
    "last_close_price = dataset_train.loc[last_date, 'Close']\n",
    "\n",
    "# Calculate the number of shares bought (excluding the initial 100 shares)\n",
    "shares_bought = shares_on_hand - initial_shares\n",
    "\n",
    "# Get the last value in the Money Spent column\n",
    "last_money_spent = end_dates_df['Money Spent'].iloc[-1]\n",
    "\n",
    "# Calculate the total value of the shares bought at the last day's closing price\n",
    "total_value_from_bought_shares = shares_bought * last_close_price\n",
    "\n",
    "# Calculate the money spent on buying the shares including losses and gains\n",
    "# Subtract the initial investment for the initial 100 shares\n",
    "money_spent_on_bought_shares = last_money_spent - initial_investment\n",
    "\n",
    "# Calculate net gain/loss from selling the bought shares\n",
    "money_earned_from_selling_bought_shares = total_value_from_bought_shares - money_spent_on_bought_shares\n",
    "\n",
    "# Print the results\n",
    "print(f\"Closing Price on the Last Day: {last_close_price}\")\n",
    "print(f\"Total Value of Bought Shares at Last Day's Closing Price: {total_value_from_bought_shares}\")\n",
    "print(f\"Money Spent on Bought Shares: {money_spent_on_bought_shares}\")\n",
    "print(f\"Net Gain/Loss from Selling Bought Shares: {money_earned_from_selling_bought_shares}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
